# Genie Framework Upgrade Diff

**Upgrade:** v2.5.14 â†’ v2.5.26-rc.2
**Generated:** 2025-11-19T18:43:23.507Z
**Diff ID:** 2025-11-19T18-43-23-401Z

---

## Summary

| Type | Count |
|------|-------|
| Added | 31 |
| Removed | 4 |
| Modified | 22 |
| **Total Changes** | **57** |

## New Files (31)

These files exist in the new version but not in your workspace:

### âœ… `.genie/agents/update.md` (4.1 KB)

<details>
<summary>View new file content</summary>

```markdown
---
name: update
description: Process framework upgrade diffs and apply changes intelligently
genie:
  executor:
    - CLAUDE_CODE
    - CODEX
    - OPENCODE
  background: false
forge:
  CLAUDE_CODE:
    model: sonnet
    dangerously_skip_permissions: true
  CODEX:
    model: gpt-5-codex
    sandbox: danger-full-access
  OPENCODE:
    model: opencode/glm-4.6
---

# Update Agent â€¢ Diff Processor & Learning Engine

## Mission

Process framework upgrade diffs to:
1. **LEARN** - Understand what changed and why
2. **APPLY** - Update framework files if needed
3. **PRESERVE** - Keep user customizations intact
4. **COMMIT** - Save changes when appropriate

**Core Principle:** The diff teaches you. Learn from it, apply selectively, preserve user work.

---

## How You're Invoked

You receive:
- Path to upgrade diff file (e.g., `.genie/upgrades/v2-5-16-to-v2-5-25.diff.md`)
- Old version (user's current)
- New version (framework latest)

Example prompt:
```
Apply framework upgrade from 2.5.16 to 2.5.25.

Agent: @.genie/code/agents/update.md
Diff: .genie/upgrades/v2-5-16-to-v2-5-25.diff.md

Process this knowledge diff:
1. Read the diff file to understand what changed
2. Analyze added/removed/modified files
3. Assess user impact
4. Generate clear update report
```

---

## Your Process

### Phase 1: Discovery - Read & Learn

1. **Read the diff file:**
   ```bash
   cat .genie/upgrades/v2-5-16-to-v2-5-25.diff.md
   ```

2. **Parse structure:**
   - Summary: Added/removed/modified counts
   - New Files: Full content to add
   - Modified Files: Unified diffs showing changes
   - Removed Files: Deprecated/deleted files

3. **Learn the intent:**
   - What patterns changed?
   - What new features emerged?
   - What old patterns were removed?
   - Why did the framework evolve this way?

### Phase 2: Implementation - Apply Selectively

**For NEW files:**
- Create if they're framework additions
- Skip if they conflict with user customizations

**For MODIFIED files:**
- Read current workspace version
- Check for user customizations
- Apply framework changes while preserving user additions
- If conflict: Document and ask user

**For REMOVED files:**
- Check if user customized them
- If customized: Preserve and warn
- If not customized: Safe to ignore (don't delete user work)

### Phase 3: Verification - Commit When Ready

**Only commit if:**
- Changes are non-breaking
- No user conflicts detected
- Tests pass (if applicable)
- Changes improve the workspace

**Commit message format:**
```
docs: apply framework upgrade v{old} â†’ v{new}

Applied {N} changes from upgrade diff:
- Added: {count} new files
- Updated: {count} framework files
- Preserved: {count} user customizations
```

---

## Success Criteria

- âœ… Diff fully analyzed and understood
- âœ… Framework changes applied intelligently
- âœ… User customizations preserved
- âœ… Clear report generated
- âœ… Commit created (if changes applied)

## Never Do

- âŒ Blindly copy all files from diff
- âŒ Overwrite user customizations
- âŒ Delete user content
- âŒ Skip learning phase
- âŒ Commit without verification

---

## Example Output

```markdown
# ğŸ”„ Framework Upgrade Applied: 2.5.16 â†’ 2.5.25

**Diff processed:** `.genie/upgrades/v2-5-16-to-v2-5-25.diff.md`
**Changes applied:** 15 files updated, 3 files added
**User content preserved:** No conflicts detected

---

## What I Learned

- **New agent:** `update/upstream-update.md` for dependency updates
- **Enhanced:** Task naming now includes source prefix `[M]` or `[C]`
- **Removed:** Legacy backup-based update flow (v2.5.13-)

---

## What I Applied

**Added:**
- `.genie/code/agents/update/upstream-update.md`
- `.genie/spells/task-naming-taxonomy.md`

**Updated:**
- `AGENTS.md` - Amendment #13 (Task Naming Taxonomy)
- `.genie/code/agents/update.md` - Simplified to diff-only processing

**Preserved:**
- All user customizations in `.genie/` remain intact
- No conflicts detected

---

## Verification

```bash
# Verify new agents available
genie list agents | grep update

# Check framework integrity
git status
```

**Commit:** `docs: apply framework upgrade v2.5.16 â†’ v2.5.25`
```

---

**Ready to process upgrade diffs! ğŸ§**
```

</details>

### âœ… `.genie/product/cli-automation.md` (7.7 KB)

<details>
<summary>View new file content</summary>

```markdown
# Genie CLI Automation Guide

Complete reference for using Genie CLI in automated workflows (cron, CI/CD, scripts).

## Quick Reference Table

| Command | Mode | Output | Use Case |
|---------|------|--------|----------|
| `genie task` | Headless | JSON | Fire-and-forget tasks |
| `genie run` | Foreground | JSON/Text | Wait for completion |
| `genie run --background` | Headless | URL | Same as task |
| `genie task monitor <id>` | Foreground | Live logs | Monitor background task |
| `genie list tasks` | Query | Table | Task status check |
| `genie view <id>` | Query | Transcript | Get task output |
| `genie resume <id>` | Interactive | JSON | Continue conversation |
| `genie stop <id>` | Control | - | Kill running task |
| `genie status` | Health | Status | System health check |

---

## 1. Fire-and-Forget Tasks (Cron/Background)

**Command:** `genie task`
- Starts task immediately
- Returns task ID
- No browser, no waiting
- Perfect for cron

### Basic Usage
```bash
# Default: JSON output with task info
genie task code/explore "Check system health"

# Output:
{
  "task_id": "abc-123...",
  "task_url": "http://localhost:8887/...",
  "agent": "code/explore",
  "executor": "CLAUDE_CODE:DEFAULT",
  "status": "started"
}
```

### Quiet Mode (No Warnings)
```bash
# Suppress version warnings (clean cron logs)
genie task --quiet code/explore "Silent task"
```

### Cron Examples
```bash
# Every 5 minutes - health check
*/5 * * * * genie task --quiet code/explore "Health check" >> /var/log/genie.log 2>&1

# Daily at 3 AM - cleanup
0 3 * * * genie task --quiet code/code-garbage-collector "Daily cleanup" >> /var/log/cleanup.log 2>&1

# Hourly - save task ID for later monitoring
0 * * * * genie task --quiet code/explore "Hourly scan" | jq -r '.task_id' > /var/log/last-task-id.txt 2>&1
```

---

## 2. Wait for Completion (Synchronous)

**Command:** `genie run`
- Waits for task to finish
- Returns output when done
- Opens browser (unless --background)

### Basic Usage
```bash
# Wait for completion, see output
genie run code/explore "Analyze codebase"

# Output: Full results JSON with status
```

### Background Mode
```bash
# Same as 'genie task' (no waiting)
genie run --background code/explore "Background task"
```

### Automation Examples
```bash
# CI/CD: Run tests and capture results
genie run --quiet code/tests "Run all tests" > test-results.json

# Script: Wait for analysis, then act on results
genie run --quiet code/analyze "Check dependencies" > deps.json
if grep -q "vulnerable" deps.json; then
  echo "Security issues found!"
  exit 1
fi
```

---

## 3. Monitor Background Tasks

**Command:** `genie task monitor <task-id>`
- Attach to running task
- Stream live logs
- Wait for completion

### Usage
```bash
# Start task in background
TASK_ID=$(genie task --quiet code/explore "Long analysis" | jq -r '.task_id')

# Monitor it later
genie task monitor $TASK_ID
```

### Automation Example
```bash
# Cron: Start task, then monitor in separate job
# Job 1 (every hour): Start task
0 * * * * genie task --quiet code/explore "Hourly check" | jq -r '.task_id' > /tmp/task-id.txt

# Job 2 (5 mins later): Monitor completion
5 * * * * genie task monitor $(cat /tmp/task-id.txt) >> /var/log/monitored.log 2>&1
```

---

## 4. Query Task Status

### List All Tasks
```bash
# Show all tasks (table format)
genie list tasks

# Sample output:
| Task ID      | Agent        | Status  | Executor         |
|--------------|--------------|---------|------------------|
| abc-123...   | code/explore | running | CLAUDE_CODE/DEFAULT |
```

### View Task Output
```bash
# Get full transcript
genie view <task-id>

# Live view (auto-refresh)
genie view --live <task-id>

# Full history
genie view --full <task-id>
```

### Automation Examples
```bash
# Check if any tasks are still running
if genie list tasks | grep -q "running"; then
  echo "Tasks still in progress"
fi

# Get specific task result
genie view abc-123 > task-output.txt
```

---

## 5. Task Control

### Stop Running Task
```bash
genie stop <task-id>
```

### Resume Conversation
```bash
# Continue from previous task
genie resume <task-id> "Follow-up question"
```

---

## 6. System Health Checks

### Check Genie Status
```bash
genie status

# Output:
ğŸ§ GENIE STATUS
ğŸ“¦ Forge Backend: ğŸŸ¢ Running
ğŸ“¡ MCP Server: ...
```

### Automation Example
```bash
# Pre-flight check before running tasks
if ! genie status | grep -q "ğŸŸ¢ Running"; then
  echo "Forge not running, starting..."
  genie &  # Start Genie server
  sleep 5
fi

# Now safe to run tasks
genie task code/explore "Check system"
```

---

## 7. Executor Control

### Override Default Executor
```bash
# Use specific executor
genie task -x OPENCODE code/explore "Use OpenCode"
genie task --executor GEMINI code/explore "Use Gemini"

# Use specific model
genie task -m "gpt-4" code/explore "Use GPT-4"
```

### Automation Example
```bash
# Distribute load across executors
for executor in CLAUDE_CODE OPENCODE GEMINI; do
  genie task -x $executor code/explore "Check $executor" &
done
wait  # Wait for all background tasks
```

---

## 8. Advanced Patterns

### Parallel Execution
```bash
# Run multiple tasks simultaneously
genie task code/explore "Task 1" &
genie task code/analyze "Task 2" &
genie task code/tests "Task 3" &
wait  # Wait for all to finish
```

### Error Handling
```bash
# Capture exit code
genie run --quiet code/tests "Run tests"
EXIT_CODE=$?

if [ $EXIT_CODE -ne 0 ]; then
  echo "Task failed with code $EXIT_CODE"
  # Notify, retry, etc.
fi
```

### Task Chaining
```bash
# Sequential tasks with error checking
TASK1=$(genie task --quiet code/explore "Step 1" | jq -r '.task_id')
genie task monitor $TASK1 || exit 1

TASK2=$(genie task --quiet code/analyze "Step 2" | jq -r '.task_id')
genie task monitor $TASK2 || exit 1

echo "Pipeline complete!"
```

### Retry Logic
```bash
# Retry failed tasks
MAX_RETRIES=3
RETRY=0

while [ $RETRY -lt $MAX_RETRIES ]; do
  genie run --quiet code/tests "Run tests" && break
  RETRY=$((RETRY + 1))
  echo "Retry $RETRY/$MAX_RETRIES"
  sleep 10
done
```

---

## 9. CI/CD Integration

### GitHub Actions Example
```yaml
- name: Run Genie Analysis
  run: |
    genie task --quiet code/analyze "Analyze PR changes" > task.json
    TASK_ID=$(jq -r '.task_id' task.json)
    genie task monitor $TASK_ID
```

### Jenkins Example
```groovy
stage('Genie Quality Check') {
  steps {
    sh 'genie run --quiet code/code-quality "Check code quality" > report.json'
    archiveArtifacts 'report.json'
  }
}
```

---

## 10. Logging & Output

### Structured Logging
```bash
# JSON output for parsing
genie task code/explore "Check" | jq '.task_id'

# Human-readable output
genie run code/explore "Generate report" | tee report.json
```

### Log Rotation
```bash
# Cron with log rotation
*/15 * * * * genie task --quiet code/explore "Check" >> /var/log/genie/$(date +\%Y\%m\%d).log 2>&1

# Keep last 7 days
find /var/log/genie/ -name "*.log" -mtime +7 -delete
```

---

## Best Practices

1. **Use `--quiet`** in cron to suppress version warnings
2. **Use `jq`** to extract specific fields from JSON output
3. **Check `genie status`** before heavy automation
4. **Save task IDs** for later monitoring/debugging
5. **Use JSON output** for programmatic parsing
6. **Set explicit executor** if you need consistency
7. **Monitor long tasks** via `genie task monitor`
8. **Handle errors** - check exit codes in scripts

---

## Common Issues

**Workspace Version Warning:**
```bash
âš ï¸  Workspace behind: workspace 2.5.19 â† global 2.5.20
```
Solution: Use `--quiet` flag or run `genie` once to sync.

**Forge Not Running:**
```bash
âŒ Forge backend unreachable
```
Solution: Start Forge with `genie` (no args) or check `genie status`.

**Task Stuck:**
```bash
genie stop <task-id>  # Kill stuck task
genie list tasks      # Check status
```
```

</details>

### âœ… `.genie/qa/generate-attribution-suggestions.cjs` (17.1 KB)

*File too large to include inline. Review directly.*

### âœ… `.genie/qa/generate-scenarios-from-bugs.cjs` (4.5 KB)

<details>
<summary>View new file content</summary>

```markdown
#!/usr/bin/env node

const { execSync } = require('child_process');
const fs = require('fs');
const path = require('path');

function fetchIssues() {
  try {
    const out = execSync('gh issue list --label type:bug --state all --json number,title,labels,state,createdAt,body --limit 1000', { encoding: 'utf8' });
    return JSON.parse(out);
  } catch (e) {
    console.error(`Error fetching issues: ${e.stderr || e.message}`);
    process.exit(1);
  }
}

function extractSections(body) {
  if (!body) return { description: 'No description provided' };
  const sections = {}; let current = 'description'; let buf = [];
  for (const line of body.split('\n')) {
    if (line.trim().startsWith('##')) { if (buf.length) sections[current] = buf.join('\n').trim(); current = line.replace(/^#+/,'').trim().toLowerCase().replace(/\s+/g,'_'); buf = []; }
    else if (line.trim().startsWith('**') && line.trim().endsWith('**')) { if (buf.length) sections[current] = buf.join('\n').trim(); current = line.replace(/\*/g,'').trim().toLowerCase().replace(/\s+/g,'_'); buf = []; }
    else buf.push(line);
  }
  if (buf.length) sections[current] = buf.join('\n').trim();
  return sections;
}

function formatScenario(issue) {
  const number = issue.number;
  const title = issue.title;
  const state = issue.state;
  const created = issue.createdAt.slice(0,10);
  const labels = (issue.labels || []).map((l) => l.name);
  const sections = extractSections(issue.body || '');
  const status = state === 'CLOSED' ? 'âœ… Fixed' : 'ğŸ”´ Open';
  let s = `## Bug #${number}: ${title}\n**Status:** ${status}\n**Labels:** ${labels.join(', ')}\n**Created:** ${created}\n**GitHub:** https://github.com/namastexlabs/automagik-genie/issues/${number}\n\n`;
  const repro = sections.reproduction_steps || sections.steps_to_reproduce;
  if (repro) s += `### Reproduction Steps\n${repro}\n\n`;
  const expected = sections.expected_behavior || sections.expected;
  if (expected) s += `### Expected Behavior\n${expected}\n\n`;
  const actual = sections.actual_behavior || sections.actual;
  if (actual) s += `### Actual Behavior\n${actual}\n\n`;
  if (sections.description && !(repro || expected)) s += `### Description\n${sections.description}\n\n`;
  s += `### Validation\n- [${state === 'OPEN' ? ' ' : 'x'}] Bug verified fixed\n- [ ] Test scenario executed\n- [ ] Regression test added\n- [ ] Documentation updated\n\n---\n\n`;
  return s;
}

function main() {
  const dryRun = process.argv.includes('--dry-run');
  console.log('ğŸ“‹ Fetching GitHub issues...');
  const issues = fetchIssues();
  console.log(`   Found ${issues.length} bug issues`);
  const ts = new Date().toISOString().replace('T',' ').replace(/\..+/, ' UTC');
  const openBugs = issues.filter((i) => i.state === 'OPEN');
  const fixedBugs = issues.filter((i) => i.state === 'CLOSED');
  let content = `# QA Scenarios from GitHub Issues\n**Auto-Generated:** ${ts}\n**Source:** GitHub Issues with label \`type:bug\`\n**Script:** \`.genie/agents/qa/workflows/auto-generated/generator.cjs\`\n\n---\n\n## Summary\n\n**Total Bugs:** ${issues.length}\n- ğŸ”´ Open: ${openBugs.length}\n- âœ… Fixed: ${fixedBugs.length}\n\n---\n\n## Open Bugs\n\n`;
  if (openBugs.length) openBugs.sort((a,b)=>a.number-b.number).forEach((i) => { content += formatScenario(i); }); else content += '*No open bugs found.*\n\n';
  content += `---\n\n## Fixed Bugs\n\n`;
  if (fixedBugs.length) fixedBugs.sort((a,b)=>b.number-a.number).forEach((i) => { content += formatScenario(i); }); else content += '*No fixed bugs found.*\n\n';
  content += `---\n\n## Usage\n\nThis file is auto-generated from GitHub issues. To update:\n\n\`\`\`bash\nnode .genie/agents/qa/workflows/auto-generated/generator.cjs\n\`\`\`\n\nTo run manually with dry-run:\n\n\`\`\`bash\nnode .genie/agents/qa/workflows/auto-generated/generator.cjs --dry-run\n\`\`\`\n\nTo automate via GitHub Actions (future):\n- Add workflow trigger: daily or on issue close\n- Run script and commit changes\n- Track regression coverage\n`;
  if (dryRun) {
    console.log('\n--- DRY RUN OUTPUT ---');
    console.log(content);
    console.log('\n--- END DRY RUN ---');
    console.log('\nâ„¹ï¸  Dry run complete. No files written.');
    return;
  }
  const outPath = path.join(__dirname, 'scenarios-from-bugs.md');
  fs.mkdirSync(path.dirname(outPath), { recursive: true });
  fs.writeFileSync(outPath, content);
  console.log(`âœ… Scenarios written to: ${outPath}`);
  console.log('\nğŸ“Š Summary:');
  console.log(`   - Total bugs: ${issues.length}`);
  console.log(`   - Open: ${openBugs.length}`);
  console.log(`   - Fixed: ${fixedBugs.length}`);
}

main();
```

</details>

### âœ… `.genie/qa/README.md` (10.4 KB)

<details>
<summary>View new file content</summary>

```markdown
# QA Coordination - Master Genie Quality Assurance Framework

**Owner:** Master Genie (QA is core identity, not separate concern)
**Principle:** No release without guarantee it's better than the previous one
**Philosophy:** Test deliberately, capture evidence thoroughly, learn continuously

---

## Quick Start

**Before any release:**
```bash
# Determine release type
# Patch (v2.5.X): Bugfix only â†’ Minimal validation
# Minor (v2.X.0): New features â†’ Comprehensive validation
# Major (vX.0.0): Breaking changes â†’ Exhaustive validation

# Execute appropriate QA level (see below)
# Collect evidence
# Generate Done Report
# Make GO/NO-GO decision
```

---

## Quality Guarantee Levels

### Level 1: Every Commit (Automated)
**Gate:** Pre-commit hooks
**Enforces:**
- Token efficiency baseline
- Cross-reference validity
- Worktree isolation
- User file protection
- Forge task linking

**Outcome:** Code quality baseline maintained

### Level 2: Every Push (Automated + Advisory)
**Gate:** Pre-push hooks + CI/CD
**Enforces:**
- All tests pass
- Commit advisory (issue/wish linkage)
- Changelog updated
- CLI smoke test

**Outcome:** Branch quality verified, main protected

### Level 3: Pre-Release (Coordinated QA Protocol)
**Gate:** Master Genie coordinates
**Granularity:** Release-type dependent

#### Patch Release (v2.5.X â†’ v2.5.X+1)
**Scope:** Bugfix only, minimal risk

**Required:**
- âœ… Automated tests pass (Level 2)
- âœ… Specific bug scenario validation
- âœ… Regression check (affected area)
- âœ… Evidence captured

**Decision:** Can release if automated tests + bug validation pass

#### Minor Release (v2.X.0 â†’ v2.X+1.0)
**Scope:** New features, moderate risk

**Required:**
- âœ… Full QA checklist execution (all 260+ items)
- âœ… QA Agent run (automated + self-improving)
- âœ… Atomic workflow validation
- âœ… Evidence for every test
- âœ… Done Report with learning summary
- âœ… Regression suite

**Decision:** Can release if >95% pass rate, no critical failures

#### Major Release (vX.0.0 â†’ vX+1.0.0)
**Scope:** Breaking changes, architectural shifts, highest risk

**Required:**
- âœ… Full QA checklist execution
- âœ… QA Agent run (multiple iterations)
- âœ… All atomic workflows validated
- âœ… Manual exploratory testing
- âœ… Performance baseline validation
- âœ… Migration path testing
- âœ… Documentation accuracy verification
- âœ… Evidence for every scenario
- âœ… Done Report with comprehensive learning

**Decision:** Can release only if 100% pass rate, zero critical issues

---

## QA Components

### Primary Checklist
**File:** `@.genie/agents/qa/checklist.md`
**Purpose:** Living operational checklist (260+ test items)
**Categories:** MCP operations, Layout/UI, Command Interface, Agent System, Session Lifecycle, Error Handling, Performance
**Maintenance:** Auto-updated by QA Agent via learn integration
**Status:** PRIMARY SOURCE OF TRUTH

### Atomic Test Scenarios
**Directory:** `@.genie/agents/qa/scenarios/`
**Purpose:** Specific, reproducible test scenarios
**Types:** Bug regression tests, feature scenarios, edge cases
**Count:** 18 scenarios (growing)
**Relationship:** Complementary to checklist (deep-dive validation)

### Bug Regression Suite
**File:** `@.genie/agents/qa/scenarios-from-bugs.md`
**Purpose:** Auto-generated from GitHub issues
**Scope:** 53 tracked bugs (7 open, 46 fixed)
**Sync:** Via `.genie/scripts/sync-qa-from-issues.cjs`
**Guarantee:** Every fixed bug becomes permanent test

### QA Agent
**File:** `@.genie/code/agents/qa.md`
**Purpose:** Automated execution + self-improvement
**Features:** Checklist execution, pattern discovery, learn integration
**Status:** Required for minor/major releases
**Output:** Done Report with evidence + learning summary

### Evidence Repository
**Directory:** `@.genie/agents/qa/evidence/`
**Purpose:** Reproducible test outputs
**Types:** CLI outputs (*.txt), logs (*.log), reports (*.md)
**Gitignore:** JSON/tmp files ignored, markdown committed
**Retention:** Permanent (evidence-backed releases)

---

## Master Genie QA Coordination Protocol

### Pre-Release Workflow

**Step 1: Determine Release Type**
```
Ask: What's changing?
- Bugfix only â†’ Patch
- New features â†’ Minor
- Breaking changes â†’ Major

Load appropriate QA level (see Quality Guarantee Levels above)
```

**Step 2: Execute Quality Gates**
```
Automated (always):
- Run: npm run test:all
- Verify: Pre-commit/pre-push hooks passing
- Check: CI/CD green (GitHub Actions)

Manual (based on level):
- Patch: Bug-specific scenarios
- Minor: Full checklist + QA Agent
- Major: Full checklist + QA Agent + exploratory
```

**Step 3: Evidence Collection**
```
For each test:
- Capture output â†’ .genie/qa/evidence/<test>-<timestamp>.txt
- Record status in checklist (âœ…/âš ï¸/âŒ)
- Document failures with reproduction steps
- Link to GitHub issues if new bugs found
```

**Step 4: Learning Integration**
```
If QA Agent discovers new patterns:
- Invoke learn agent with teaching prompt
- Checklist auto-updated
- New test items available for future runs

Example:
mcp__genie__run with agent="learn" and prompt="
Teaching: QA Checklist Update
Discovery: New validation pattern found...
Implementation: Append to checklist.md under <category>
"
```

**Step 5: Release Decision**
```
Calculate:
- Pass rate = (âœ… count) / (total tests)
- Critical failures = (âŒ count where severity=critical)

Decision Matrix:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Type     â”‚ Pass Rate  â”‚ Critical Allowed â”‚ Decision â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Patch    â”‚ >90%       â”‚ 0                â”‚ GO/NO-GO â”‚
â”‚ Minor    â”‚ >95%       â”‚ 0                â”‚ GO/NO-GO â”‚
â”‚ Major    â”‚ 100%       â”‚ 0                â”‚ GO/NO-GO â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

If NO-GO:
- Document blockers in GitHub issues
- Defer release until resolved
- Re-run QA after fixes
```

**Step 6: Done Report**
```
Generate using template:
@.genie/product/templates/qa-done-report-template.md

Include:
- Test matrix (all scenarios + results)
- Evidence references (file paths)
- Bugs found/fixed (with GitHub issue links)
- Learning summary (new patterns discovered)
- Coverage analysis (% validated)
- Release recommendation (GO/NO-GO + reasoning)

Save to: .genie/qa/evidence/done-report-<version>-<timestamp>.md
```

---

## Self-Improvement Loop

Every QA run makes the system smarter:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ QA Run       â”‚
â”‚ (Manual/Auto)â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ New Pattern  â”‚
â”‚ Discovered   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Learn Agent  â”‚
â”‚ Invoked      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Checklist    â”‚
â”‚ Updated      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Next QA Run  â”‚
â”‚ Includes New â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Result:** Checklist grows organically, regression-proof, continuously improving

---

## Directory Structure

```
.genie/qa/
â”œâ”€â”€ README.md                    # This file (Master coordination)
â”œâ”€â”€ checklist.md                 # Living operational checklist (PRIMARY)
â”œâ”€â”€ scenarios-from-bugs.md       # Auto-generated regression tests
â”œâ”€â”€ evidence/                    # Test outputs
â”‚   â”œâ”€â”€ *.txt                   # CLI outputs (committed)
â”‚   â”œâ”€â”€ *.log                   # Logs (gitignored)
â”‚   â”œâ”€â”€ *.md                    # Reports (committed)
â”‚   â””â”€â”€ *.json                  # Structured data (gitignored)
â””â”€â”€ workflows/                   # Workflow-specific QA
    â”œâ”€â”€ voice-boot-qa-workflow.md
    â””â”€â”€ MIGRATION_PLAN.md

.genie/qa/scenarios/        # Atomic test scenarios (18 files)
â”œâ”€â”€ README.md                    # Index (bidirectional links)
â”œâ”€â”€ mcp-operations.md
â”œâ”€â”€ session-lifecycle.md
â”œâ”€â”€ bug-*.md                     # Bug regression tests
â””â”€â”€ ...

.genie/code/agents/qa.md         # QA Agent (automation + self-improvement)

.genie/product/docs/qa-checklist.md  # Template (canonical format)
.genie/product/templates/qa-done-report-template.md  # Report template
```

---

## Quick Reference

**Run full QA for minor release:**
```bash
# Option 1: QA Agent (automated + self-improving)
mcp__genie__run with agent="qa" and prompt="Execute full QA for v2.X.0 release"

# Option 2: Manual (use checklist directly)
# Load: @.genie/agents/qa/checklist.md
# Execute each test item
# Capture evidence
# Update status
```

**Run bug-specific validation:**
```bash
# Find atomic workflow
# Example: @.genie/agents/qa/scenarios/bug-102-session-collision.md
# Execute test steps
# Capture evidence
# Update regression suite
```

**Generate Done Report:**
```bash
# Load template: @.genie/product/templates/qa-done-report-template.md
# Fill in: test matrix, evidence, bugs, learning, decision
# Save to: .genie/qa/evidence/done-report-<version>-<timestamp>.md
```

---

## Success Metrics

**Quality Guarantee:**
- ğŸ¯ Zero regressions in production
- ğŸ¯ 100% evidence-backed releases
- ğŸ¯ Continuous checklist improvement
- ğŸ¯ Fast feedback (pre-commit catches early)

**Release Confidence:**
- Patch: Can ship in <1 hour
- Minor: Can ship in <4 hours
- Major: Can ship in <1 day

**Learning Rate:**
- Every bug â†’ permanent test
- Every QA run â†’ 1-3 new patterns discovered
- Checklist grows organically, never shrinks

---

## Key Principles

1. **Master Genie coordinates** - QA is my responsibility, part of my identity
2. **No release without evidence** - Every test captures proof
3. **Granularity matches risk** - Patch=light, Major=exhaustive
4. **Self-improving** - Learn from every run
5. **Regression-proof** - Bugs become permanent tests
6. **Fast feedback** - Catch issues at commit time
7. **Human-friendly** - Clear reports, obvious decisions

---

**Master Genie says:** Quality is not optional. It's who I am. Every release is better than the last, guaranteed. ğŸ¯
```

</details>

### âœ… `.genie/qa/scenarios-from-bugs.md` (59.2 KB)

*File too large to include inline. Review directly.*

### âœ… `.genie/qa/scenarios-metadata-suggestions.yaml` (64.1 KB)

*File too large to include inline. Review directly.*

### âœ… `.genie/qa/scenarios/README.md` (6.7 KB)

<details>
<summary>View new file content</summary>

```markdown
# Atomic QA Workflows - Scenario Index

**Purpose:** Specific, reproducible test scenarios complementing the comprehensive checklist
**Relationship:** Deep-dive validation for specific features/bugs (complements broad checklist coverage)
**Master Coordination:** `@.genie/qa/README.md`
**Checklist Reference:** `@.genie/agents/qa/checklist.md`

---

## Philosophy: Vertical Growth

Each QA scenario is atomic, focused, and independently executable. This enables:
- Vertical scaling (add scenarios without touching existing)
- Bug-driven testing (every bug â†’ permanent regression test)
- Feature-specific validation (deep-dive beyond checklist)
- Agent automation (scenarios can be run by QA agent)

---

## How to Use

**For bug regression:**
1. Find `bug-XXX-*.md` file matching GitHub issue number
2. Execute test steps sequentially
3. Capture evidence in `.genie/qa/evidence/`
4. Update status in main checklist at referenced section

**For feature validation:**
1. Find scenario matching feature (e.g., `mcp-operations.md`)
2. Execute all test cases
3. Link results to checklist items
4. Report outcomes to Master Genie for release decision

**For performance benchmarks:**
1. Find latency/timing scenarios (e.g., `agent-listing-latency.md`)
2. Measure and compare against baseline
3. Document in evidence directory
4. Update Performance section in checklist

---

## Scenario Index

### MCP Operations (Core Functionality)
- **mcp-operations.md** - Comprehensive MCP tool testing
  - Coverage: list, run, view, resume, stop
  - Checklist: `@.genie/agents/qa/checklist.md` (MCP Agent Operations section)
  - Status: Active (primary MCP validation)

- **mcp-agent-start-failure.md** - Agent startup error handling
  - Coverage: Invalid agent names, error messages
  - Checklist: MCP Agent Operations â†’ Error Scenarios
  - Status: Active

- **mcp-session-resume-life-cycle.md** - Resume workflow validation
  - Coverage: Session resumption, context preservation
  - Checklist: Session Lifecycle â†’ Resumption
  - Status: Active

### Session Lifecycle
- **session-lifecycle.md** - Complete session workflow testing
  - Coverage: Creation, resumption, termination
  - Checklist: Session Lifecycle (all items)
  - Status: Active (primary session validation)

- **session-id-collision.md** - ID uniqueness validation
  - Coverage: Concurrent session creation, uniqueness checks
  - Checklist: Session Lifecycle â†’ Session ID generation
  - Status: Active

- **session-list-consistency.md** - List accuracy validation
  - Coverage: Session list display, status accuracy
  - Checklist: Session Lifecycle â†’ Session tracking
  - Status: Active

- **session-running-stuck.md** - Stuck session handling
  - Coverage: Timeout, zombie sessions, cleanup
  - Checklist: Session Lifecycle â†’ Termination
  - Status: Active

### Bug Regression Tests
- **bug-66-session-persistence.md** - Session state preservation (GitHub #66)
  - Coverage: Session data persists across restarts
  - Checklist: Session Lifecycle â†’ Context preservation
  - Status: âœ… Fixed (regression test)

- **bug-90-full-transcript.md** - Full transcript truncation (GitHub #90)
  - Coverage: full=true returns complete conversation
  - Checklist: Session Lifecycle â†’ View full session
  - Status: âœ… Fixed (regression test)

- **bug-92-zombie-sessions.md** - Zombie session cleanup (GitHub #92)
  - Coverage: Proper session termination
  - Checklist: Session Lifecycle â†’ Graceful stop
  - Status: âœ… Fixed (regression test)

- **bug-102-session-collision.md** - Session ID collision (GitHub #102)
  - Coverage: Timestamp+random prevents collisions
  - Checklist: Session Lifecycle â†’ Session ID generation
  - Status: âœ… Fixed (regression test)

- **bug-xxx-background-launch.md** - Background launch issues
  - Coverage: Background agent startup
  - Checklist: Agent System â†’ Agent execution
  - Status: Regression test

### CLI & Command Interface
- **cli-commands.md** - CLI command validation
  - Coverage: Help, arguments, flags
  - Checklist: Command Interface (all items)
  - Status: Active

- **cli-output-legacy-commands.md** - Legacy command compatibility
  - Coverage: Backward compatibility checks
  - Checklist: Command Interface â†’ Help accuracy
  - Status: Active

### Installation & Setup
- **installation-flow.md** - Installation workflow testing
  - Coverage: Clean-slate setup, MCP config, Forge integration
  - Checklist: `@.genie/agents/qa/install-simulation.md`
  - Status: Active

### Performance Benchmarks
- **agent-listing-latency.md** - List agents performance
  - Coverage: `mcp__genie__list_agents` latency
  - Checklist: Performance â†’ List agents latency
  - Baseline: <100ms
  - Status: Active

- **background-launch-timeout-argmax.md** - Timeout handling performance
  - Coverage: Agent startup time, timeout behavior
  - Checklist: Performance â†’ Agent startup time
  - Status: Baseline measurement

---

## Scenario Structure Template

```markdown
---
name: qa/<scenario-name>
description: <one-line purpose>
---

# QA Workflow â€¢ <Scenario Name>

## Test Scenario
<Description of what's being tested>

## Test Suite

### <Test Case 1>
**Command:**
```
<executable command>
```

**Expected Evidence:**
<what should happen>

**Verification:**
- [ ] <check 1>
- [ ] <check 2>

---

## Execution Notes
**Run via:**
```
mcp__genie__run with agent="qa/<scenario-name>" and prompt="Execute all tests"
```

**Evidence capture:**
- Save to `.genie/qa/evidence/<scenario>-<timestamp>.txt`
```

---

## Adding New Scenarios

**When to create:**
- New feature needs deep-dive validation
- Bug fix requires regression test
- Edge case discovered during QA run
- Performance baseline measurement needed

**How to create:**
1. Copy template structure above
2. Define test cases with executable commands
3. Specify expected evidence
4. Add reference in `@.genie/agents/qa/checklist.md` under appropriate section
5. Link back to this workflow file
6. Update this README index

**Checklist Integration:**
- Every scenario should reference checklist section
- Checklist items should reference atomic workflows for deep-dive
- Bidirectional linking (scenario â†” checklist)

---

## Execution Patterns

**Individual scenario:**
```
mcp__genie__run with agent="qa/<scenario-name>" and prompt="Execute tests"
```

**Category sweep (e.g., all session tests):**
```
# Run via QA Agent
mcp__genie__run with agent="qa" and prompt="Execute all session lifecycle scenarios"
```

**Regression suite (all bug scenarios):**
```
# Run via QA Agent
mcp__genie__run with agent="qa" and prompt="Execute all bug regression tests (bug-*.md)"
```

---

**Master Genie coordination:** Every scenario is evidence-backed, reproducible, and linked to comprehensive checklist. No duplication, only depth. Quality is guaranteed. ğŸ¯
```

</details>

### âœ… `.genie/README.md` (6.5 KB)

<details>
<summary>View new file content</summary>

```markdown
# ğŸ§ GENIE Framework
**The Universal Agent Orchestration Framework**

GENIE is a self-contained framework for managing AI agent conversations, wishes, and orchestration. It works with any AI system (Claude, Cursor, etc.) and provides consistent tooling for agent management.

## Structure

```
.genie/
â”œâ”€â”€ agents/          # Agent personalities (forge-coder, forge-tests, etc.)
â”œâ”€â”€ wishes/          # Structured development wishes
â”œâ”€â”€ reports/         # Done Reports and execution reports
â”œâ”€â”€ cli/            # Command-line tools
â”‚   â””â”€â”€ genie.ts    # Universal agent conversation manager
â”œâ”€â”€ templates/      # Wish and report templates
â””â”€â”€ knowledge/      # Shared knowledge base
```

## Quick Start

### Using MCP Tools

Start a conversation with any agent:
```
mcp__genie__run with agent="template-implementor" and prompt="implement authentication"
```

Continue the conversation:
```
mcp__genie__resume with sessionId="<session-id>" and prompt="add OAuth support"
```

List active sessions:
```
mcp__genie__list_sessions
```

### Available Agents

- **forge-coder** - Feature implementation agent
- **forge-tests** - Test writing expert
- **forge-master** - Task creation and orchestration
- **forge-quality** - Code quality enforcement
- **forge-hooks** - Hook configuration agent
- **forge-qa-tester** - QA and testing coordinator
- **learn** - Unified behavioral learning and improvement

#### Local agents in this repo
- **evaluator** â€“ {{DOMAIN}} evaluation rubric and scoring prompt (`.genie/agents/evaluator.md`)
- **refactorer** â€“ Prompt refactoring agent (`.genie/agents/refactorer.md`)
- **rules-integrator** â€“ Minimal, non-destructive rules updater (`.genie/agents/rules-integrator.md`)

---

<!-- NEURAL_TREE_START -->
## Agent Tree

**Auto-generated** from `.genie/` folder structure

**Summary:**
- Code agents: 24
- Code workflows: 0
- Git workflows: 0
- Create agents: 5
- Orchestrators: 0
- **Total: 29 agents**

### Code Collective

**Orchestrator:** `code`

**Agents:**
- **audit**
- **challenge**
- **change-reviewer**
- **code-garbage-collector**
- **code-quality**
- **commit**
- **commit-suggester**
- **consensus**
- **docgen**
- **explore**
- **fix**
- **git** â†’ `report`, `issue`, `pr`, `git`
- **implementor** â†’ `implementor`
- **install** â†’ `wish`, `forge`, `review`
- **issue-creator**
- **polish** â†’ `polish`
- **qa**
- **refactor**
- **release** â†’ `commit`, `release`
- **roadmap** â†’ `roadmap`
- **tests** â†’ `tests`
- **tracer**
- **update**
- **vibe** â†’ `sleepy`, `$agent`

### Create Collective

**Orchestrator:** `create`

**Agents:**
- **editor**
- **install**
- **README**
- **researcher**
- **writer**
<!-- NEURAL_TREE_END -->

---

### For AI Agents (Claude, etc.)

Instead of using one-shot Task tools, use MCP for full conversations:

```
# Start implementing a wish
mcp__genie__run with agent="template-implementor" and prompt=" implement Group A"

# Continue with error handling
mcp__genie__resume with sessionId="<session-id>" and prompt="tests failing, debug the issue"
```

## Conventions

### Wishes
- Stored in `.genie/wishes/`
- Named as `<feature>-wish.md`
- Contain structured implementation plans

### Reports
- Done Reports in `.genie/wishes/<slug>/reports/`
- Named as `done-<agent>-<slug>-<YYYYMMDDHHmm>.md`
- Document execution evidence and risks

### Agents
- Defined in `.genie/agents/`
- Markdown files with structured prompts
- Loaded as Codex base instructions

## Configuration

Agents configure their execution environment via two independent settings in YAML frontmatter:

### Sandbox (File System Access)
- **read-only** - Read files only (analysis, review agents)
- **workspace-write** - Read/write in workspace (default, implementation agents)
- **danger-full-access** - Full system access (rare, externally sandboxed only)

### Approval Policy (Human Interaction)
- **never** - No approvals (fully automated)
- **on-failure** - Ask when commands fail (default)
- **on-request** - Ask for risky operations (interactive)
- **untrusted** - Ask for everything (high-security)

### Agent Front Matter Reference

Each file in `.genie/agents/` can override executor behaviour by adding a YAML
front matter block. The CLI loads that block, merges it with `config.yaml`, and
translates it to `npx -y @namastexlabs/codex@0.43.0-alpha.5 exec` flags. The structure is:

```yaml
---
name: my-agent
description: Optional prompt summary
genie:
  executor: codex            # Which executor profile to use (defaults to `codex`)
  background: false          # Force foreground (otherwise inherits CLI default)
  binary: npx                # Override executable name if needed
  packageSpec: "@namastexlabs/codex@0.43.0-alpha.5"
  sessionsDir: .genie/state/agents/codex-sessions
  sessionExtractionDelayMs: 2000
  exec:
    fullAuto: true           # --full-auto
    model: gpt-5-codex       # -m
    sandbox: workspace-write # -s
    profile: null            # -p
    includePlanTool: true    # --include-plan-tool
    search: true             # --search
    skipGitRepoCheck: true   # --skip-git-repo-check
    json: false              # --json
    experimentalJson: true   # --experimental-json
    color: never             # --color
    cd: null                 # -C <path>
    outputSchema: null       # --output-schema
    outputLastMessage: null  # --output-last-message
    reasoningEffort: high    # -c reasoning.effort="high"
    images: []               # -i <path> for each entry
    additionalArgs: []       # Raw flags appended verbatim
  resume:
    includePlanTool: true
    search: true
    last: false              # --last when resuming
    additionalArgs: []
---
```

Supported keys are derived from the codex executor defaults
(`src/cli/executors/codex.ts` - if it exists). Any value omitted in front matter keeps
the executor default. Unknown keys under `genie.exec` become additional `npx ...
exec` overrides, so the safest pattern is to use the fields above. Put extra
flags in `additionalArgs` to avoid accidentally shadowing future options.

## Integration

### With Claude
Claude continues to use its specific configuration in `.claude/` but leverages GENIE for agent orchestration.

### With Other Systems
Copy the `.genie/` directory to any project to enable GENIE orchestration.

## Future Extensions

- Session history and search
- Background execution monitoring
- Multi-session per agent support
- Conversation export and analysis

---

*GENIE: Making agent orchestration magical* ğŸ§âœ¨
# Test $(date +%s)
# Test round 3 - $(date +%s)
# Test optimization 1761165180
# Final test $(date +%s)
```

</details>

### âœ… `.genie/scripts/commit-advisory.cjs` (17.6 KB)

*File too large to include inline. Review directly.*

### âœ… `.genie/scripts/detect-teaching-signal.cjs` (3.6 KB)

<details>
<summary>View new file content</summary>

```markdown
#!/usr/bin/env node
/**
 * detect-teaching-signal.js
 *
 * Purpose: Auto-detect teaching moments in conversation transcripts
 * Triggers: "Let me teach you", "You should have", "From now on", "That was wrong because"
 * Action: Log teaching moment and suggest invoking learn agent
 *
 * Usage: node detect-teaching-signal.js <transcript-file>
 *
 * Part of: Skills Prioritization & Architecture Automation (Wish #107)
 */

const fs = require('fs');
const path = require('path');

// Teaching signal patterns (from routing.md lines 108-114)
const TEACHING_PATTERNS = [
  /let me teach you/i,
  /you should have/i,
  /from now on/i,
  /that was wrong because/i,
  /next time.*do this/i,
  /remember to always/i,
  /important lesson/i,
  /key learning/i
];

/**
 * Detect teaching signals in a transcript
 * @param {string} transcriptPath - Path to conversation transcript
 * @returns {Array} - Array of detected teaching moments with context
 */
function detectTeachingSignals(transcriptPath) {
  if (!fs.existsSync(transcriptPath)) {
    console.error(`âŒ Transcript file not found: ${transcriptPath}`);
    process.exit(1);
  }

  const content = fs.readFileSync(transcriptPath, 'utf-8');
  const lines = content.split('\n');

  const teachingMoments = [];

  lines.forEach((line, index) => {
    TEACHING_PATTERNS.forEach(pattern => {
      if (pattern.test(line)) {
        teachingMoments.push({
          line: index + 1,
          content: line.trim(),
          pattern: pattern.source,
          context: getContext(lines, index)
        });
      }
    });
  });

  return teachingMoments;
}

/**
 * Get surrounding context for a teaching moment
 * @param {Array} lines - All lines in transcript
 * @param {number} index - Index of teaching moment
 * @returns {string} - Context lines (Â±2 lines)
 */
function getContext(lines, index) {
  const start = Math.max(0, index - 2);
  const end = Math.min(lines.length, index + 3);
  return lines.slice(start, end).join('\n');
}

/**
 * Generate learn agent invocation suggestion
 * @param {Array} moments - Detected teaching moments
 * @returns {string} - Suggested command
 */
function generateLearnSuggestion(moments) {
  if (moments.length === 0) {
    return 'âœ… No teaching signals detected.';
  }

  const suggestions = moments.map((moment, i) => {
    return `
ğŸ“š Teaching Moment #${i + 1} (Line ${moment.line}):
   "${moment.content}"

   Pattern matched: ${moment.pattern}

   Context:
   ${moment.context.split('\n').map(l => '   ' + l).join('\n')}

   âœ… Action: Invoke learn agent
   Command: mcp__genie__run agent="learn" prompt="Teaching: [describe learning]"
`;
  }).join('\n---\n');

  return `
ğŸ” Detected ${moments.length} teaching signal(s):
${suggestions}

âš ï¸ CRITICAL: According to routing.md (lines 106-127), teaching moments should trigger learn agent invocation.
   Do NOT skip this step - document the learning immediately.
`;
}

// Main execution
if (require.main === module) {
  const args = process.argv.slice(2);

  if (args.length === 0) {
    console.log(`
Usage: node detect-teaching-signal.js <transcript-file>

Detects teaching moments in conversation transcripts and suggests learn agent invocation.

Teaching patterns:
${TEACHING_PATTERNS.map(p => `  - ${p.source}`).join('\n')}
`);
    process.exit(0);
  }

  const transcriptPath = path.resolve(args[0]);
  const moments = detectTeachingSignals(transcriptPath);
  const suggestion = generateLearnSuggestion(moments);

  console.log(suggestion);

  // Exit with non-zero if teaching moments found (for CI/CD integration)
  process.exit(moments.length > 0 ? 1 : 0);
}

module.exports = { detectTeachingSignals, generateLearnSuggestion };
```

</details>

### âœ… `.genie/scripts/fix-agent-models.js` (7.7 KB)

<details>
<summary>View new file content</summary>

```markdown
#!/usr/bin/env node

/**
 * Fix Agent Frontmatter Models
 *
 * Corrects model configurations in agent frontmatter:
 * - Executor order: CLAUDE_CODE, CODEX, OPENCODE
 * - CLAUDE_CODE: sonnet (keep existing haiku, opus, etc.)
 * - CODEX: gpt-5-codex
 * - OPENCODE: opencode/glm-4.6 (replace all grok models)
 */

const fs = require('fs');
const path = require('path');
const yaml = require('yaml');

const DRY_RUN = process.argv.includes('--dry-run');

// ANSI colors
const colors = {
  reset: '\x1b[0m',
  bright: '\x1b[1m',
  dim: '\x1b[2m',
  red: '\x1b[31m',
  green: '\x1b[32m',
  yellow: '\x1b[33m',
  blue: '\x1b[34m',
  cyan: '\x1b[36m',
};

function log(message, color = 'reset') {
  console.log(`${colors[color]}${message}${colors.reset}`);
}

function findAgentFiles(dir, files = []) {
  const entries = fs.readdirSync(dir, { withFileTypes: true });

  for (const entry of entries) {
    const fullPath = path.join(dir, entry.name);

    if (entry.isDirectory()) {
      // Skip non-agent directories
      const skipDirs = ['spells', 'workflows', 'reports', 'state', 'product', 'qa',
                        'wishes', 'scripts', 'utilities', 'specs', '.cache',
                        'node_modules', '.git', 'backups'];
      if (!skipDirs.includes(entry.name)) {
        findAgentFiles(fullPath, files);
      }
    } else if (entry.isFile() && entry.name.endsWith('.md')) {
      // Skip README and AGENTS files
      const name = path.basename(entry.name, '.md');
      if (!['README', 'AGENTS'].includes(name.toUpperCase())) {
        files.push(fullPath);
      }
    }
  }

  return files;
}

function extractFrontmatter(content) {
  const regex = /^---\r?\n([\s\S]*?)\r?\n---\r?\n([\s\S]*)$/;
  const match = content.match(regex);

  if (!match) {
    return null;
  }

  try {
    const frontmatter = yaml.parse(match[1]);
    const body = match[2];
    return { frontmatter, body, rawYaml: match[1] };
  } catch (e) {
    return null;
  }
}

function getClaudeModel(existingModel) {
  // Keep existing Claude models (haiku, opus, sonnet-4-5, etc.)
  // Default to sonnet if none specified
  if (!existingModel) return 'sonnet';

  const claudeModels = ['haiku', 'opus', 'sonnet', 'sonnet-4-5', 'sonnet-4.5'];
  const normalized = existingModel.toLowerCase();

  // If it's already a valid Claude model, keep it
  if (claudeModels.some(m => normalized.includes(m))) {
    return existingModel;
  }

  // Otherwise default to sonnet
  return 'sonnet';
}

function fixFrontmatter(frontmatter) {
  if (!frontmatter.genie || !frontmatter.genie.executor) {
    return { changed: false, frontmatter };
  }

  let changed = false;
  const newFrontmatter = JSON.parse(JSON.stringify(frontmatter));

  // Ensure executor is an array
  const executors = Array.isArray(newFrontmatter.genie.executor)
    ? newFrontmatter.genie.executor
    : [newFrontmatter.genie.executor];

  // Fix executor order and ensure all three are present
  const targetExecutors = ['CLAUDE_CODE', 'CODEX', 'OPENCODE'];
  const hasExecutors = targetExecutors.filter(e => executors.includes(e));

  if (hasExecutors.length > 0) {
    newFrontmatter.genie.executor = targetExecutors;
    if (JSON.stringify(frontmatter.genie.executor) !== JSON.stringify(targetExecutors)) {
      changed = true;
    }
  }

  // Initialize forge if not present
  if (!newFrontmatter.forge) {
    newFrontmatter.forge = {};
  }

  // Fix CLAUDE_CODE model
  if (executors.includes('CLAUDE_CODE')) {
    const existingClaudeModel = newFrontmatter.forge.CLAUDE_CODE?.model;
    const newClaudeModel = getClaudeModel(existingClaudeModel);

    if (!newFrontmatter.forge.CLAUDE_CODE) {
      newFrontmatter.forge.CLAUDE_CODE = {};
    }

    if (newFrontmatter.forge.CLAUDE_CODE.model !== newClaudeModel) {
      newFrontmatter.forge.CLAUDE_CODE.model = newClaudeModel;
      changed = true;
    }
  }

  // Fix CODEX model
  if (executors.includes('CODEX')) {
    if (!newFrontmatter.forge.CODEX) {
      newFrontmatter.forge.CODEX = {};
    }

    if (newFrontmatter.forge.CODEX.model !== 'gpt-5-codex') {
      newFrontmatter.forge.CODEX.model = 'gpt-5-codex';
      changed = true;
    }
  }

  // Fix OPENCODE model (replace grok with glm-4-plus)
  if (executors.includes('OPENCODE')) {
    if (!newFrontmatter.forge.OPENCODE) {
      newFrontmatter.forge.OPENCODE = {};
    }

    const existingModel = newFrontmatter.forge.OPENCODE.model || '';
    const isGrok = existingModel.includes('grok') || existingModel.includes('xai');

    if (!newFrontmatter.forge.OPENCODE.model || isGrok) {
      newFrontmatter.forge.OPENCODE.model = 'opencode/glm-4.6';
      changed = true;
    }
  }

  return { changed, frontmatter: newFrontmatter };
}

function formatYaml(obj) {
  // Custom YAML formatting to match existing style
  return yaml.stringify(obj, {
    indent: 2,
    lineWidth: 0,
    defaultStringType: 'PLAIN',
    defaultKeyType: 'PLAIN',
  });
}

function processFile(filePath) {
  const content = fs.readFileSync(filePath, 'utf-8');
  const parsed = extractFrontmatter(content);

  if (!parsed) {
    log(`  âŠ˜ No valid frontmatter`, 'dim');
    return { skipped: true };
  }

  const { changed, frontmatter: newFrontmatter } = fixFrontmatter(parsed.frontmatter);

  if (!changed) {
    log(`  âœ“ Already correct`, 'dim');
    return { skipped: true };
  }

  // Show changes
  const oldExecutors = parsed.frontmatter.genie?.executor || [];
  const newExecutors = newFrontmatter.genie?.executor || [];
  const oldForge = parsed.frontmatter.forge || {};
  const newForge = newFrontmatter.forge || {};

  log(`  Changes:`, 'yellow');

  if (JSON.stringify(oldExecutors) !== JSON.stringify(newExecutors)) {
    log(`    executors: ${JSON.stringify(oldExecutors)} â†’ ${JSON.stringify(newExecutors)}`, 'cyan');
  }

  for (const executor of ['CLAUDE_CODE', 'CODEX', 'OPENCODE']) {
    const oldModel = oldForge[executor]?.model;
    const newModel = newForge[executor]?.model;

    if (oldModel !== newModel) {
      log(`    ${executor}.model: ${oldModel || '(none)'} â†’ ${newModel}`, 'cyan');
    }
  }

  if (DRY_RUN) {
    log(`  [DRY RUN] Would update file`, 'yellow');
    return { changed: true, dryRun: true };
  }

  // Write updated file
  const newYaml = formatYaml(newFrontmatter);
  const newContent = `---\n${newYaml}---\n${parsed.body}`;
  fs.writeFileSync(filePath, newContent, 'utf-8');

  log(`  âœ“ Updated`, 'green');
  return { changed: true };
}

function main() {
  const genieRoot = path.join(__dirname, '..');

  log('\n=== Agent Frontmatter Model Fixer ===\n', 'bright');

  if (DRY_RUN) {
    log('ğŸ” DRY RUN MODE - No files will be modified\n', 'yellow');
  }

  // Find all agent files
  const agentDirs = [
    path.join(genieRoot, 'agents'),
    path.join(genieRoot, 'code', 'agents'),
    path.join(genieRoot, 'create', 'agents'),
    path.join(genieRoot, 'neurons'),
  ];

  let allFiles = [];
  for (const dir of agentDirs) {
    if (fs.existsSync(dir)) {
      const files = findAgentFiles(dir);
      allFiles = allFiles.concat(files);
    }
  }

  log(`Found ${allFiles.length} agent files\n`, 'bright');

  let stats = {
    total: 0,
    changed: 0,
    skipped: 0,
  };

  for (const file of allFiles) {
    const relativePath = path.relative(genieRoot, file);
    log(`\n${relativePath}`, 'blue');

    stats.total++;
    const result = processFile(file);

    if (result.changed) {
      stats.changed++;
    } else if (result.skipped) {
      stats.skipped++;
    }
  }

  // Summary
  log('\n' + '='.repeat(50), 'dim');
  log('\nSummary:', 'bright');
  log(`  Total files: ${stats.total}`, 'dim');
  log(`  Changed: ${stats.changed}`, stats.changed > 0 ? 'green' : 'dim');
  log(`  Skipped: ${stats.skipped}`, 'dim');

  if (DRY_RUN && stats.changed > 0) {
    log('\nğŸ’¡ Run without --dry-run to apply changes', 'yellow');
  }

  log('');
}

main();
```

</details>

### âœ… `.genie/scripts/forge-task-link.cjs` (7.8 KB)

<details>
<summary>View new file content</summary>

```markdown
#!/usr/bin/env node

/**
 * forge-task-link.js
 *
 * Pre-commit hook: Automatically link Forge task â†’ Wish when first commit happens in worktree
 *
 * Reverse-extraction algorithm:
 * 1. Get worktree directory name (e.g., 35a4-test-forge-metad)
 * 2. Extract attempt ID prefix (first 4 chars: 35a4)
 * 3. Extract task abbreviation (remainder: test-forge-metad)
 * 4. Search .genie/wishes/ for matching wish slug
 * 5. Update SESSION-STATE.md with linkage
 * 6. Invoke Forge task linking workflow (optional)
 *
 * Exit codes:
 * - 0: Successfully linked or already linked
 * - 1: Warning (couldn't find wish, but continue anyway)
 * - 2: Error (blocking issue)
 */

const fs = require('fs');
const path = require('path');
const { execSync } = require('child_process');

class ForgeTaskLinker {
  constructor() {
    this.repoRoot = this.findRepoRoot();
    this.wishesDir = path.join(this.repoRoot, '.genie', 'wishes');
    this.sessionStateFile = path.join(this.repoRoot, '.genie', 'SESSION-STATE.md');
    this.warnings = [];
    this.errors = [];
  }

  log(color, emoji, msg) {
    const colors = {
      reset: '\x1b[0m',
      red: '\x1b[31m',
      green: '\x1b[32m',
      yellow: '\x1b[33m',
      blue: '\x1b[34m',
      cyan: '\x1b[36m'
    };
    console.log(`${colors[color] || ''}${emoji} ${msg}${colors.reset}`);
  }

  /**
   * Find repository root
   */
  findRepoRoot() {
    try {
      return execSync('git rev-parse --show-toplevel', {
        encoding: 'utf8',
        stdio: ['pipe', 'pipe', 'ignore']
      }).trim();
    } catch {
      return process.cwd();
    }
  }

  /**
   * Detect if we're in a Forge worktree
   */
  isForgeWorktree() {
    try {
      const gitDir = execSync('git rev-parse --git-dir', {
        encoding: 'utf8',
        stdio: ['pipe', 'pipe', 'ignore']
      }).trim();

      // Forge worktrees have .git as a file (gitdir reference)
      const gitPath = path.join(this.repoRoot, gitDir);
      return fs.existsSync(gitPath) && fs.statSync(gitPath).isFile();
    } catch {
      return false;
    }
  }

  /**
   * Get current branch
   */
  getCurrentBranch() {
    try {
      return execSync('git rev-parse --abbrev-ref HEAD', {
        encoding: 'utf8',
        stdio: ['pipe', 'pipe', 'ignore']
      }).trim();
    } catch {
      return null;
    }
  }

  /**
   * Extract Forge metadata from branch name
   * Branch patterns:
   * - forge/<attempt-id-prefix>-<abbreviated-title> (Forge worktrees)
   * - feat/<abbreviated-title> (Manual feature branches)
   */
  extractForgeMetadata(branch) {
    // Try forge/ pattern first (Forge worktrees: forge/35a4-test-forge-metad)
    let match = branch.match(/^forge\/([a-f0-9]{4})-(.*?)$/);
    if (match) {
      return {
        attemptIdPrefix: match[1],
        taskAbbrev: match[2],
        fullBranchName: branch,
        isForgeBranch: true
      };
    }

    // Try feat/ pattern (Manual branches: feat/skills-prioritization)
    match = branch.match(/^feat\/(.+?)$/);
    if (match) {
      // Generate pseudo attempt ID from branch name (first 4 chars of first word)
      const taskName = match[1];
      const firstWord = taskName.split('-')[0];
      const pseudoId = firstWord.substring(0, 4).padEnd(4, '0').toLowerCase();

      return {
        attemptIdPrefix: `feat_${pseudoId}`,
        taskAbbrev: taskName,
        fullBranchName: branch,
        isForgeBranch: false
      };
    }

    return null;
  }

  /**
   * Find matching wish by abbreviation
   */
  findMatchingWish(taskAbbrev) {
    if (!fs.existsSync(this.wishesDir)) {
      this.warnings.push(`Wishes directory not found: ${this.wishesDir}`);
      return null;
    }

    const wishdirs = fs.readdirSync(this.wishesDir);

    // Exact match first
    if (wishdirs.includes(taskAbbrev)) {
      return taskAbbrev;
    }

    // Fuzzy match: check if wish slug contains parts of abbreviation
    const abbrevParts = taskAbbrev.split('-');
    for (const wishDir of wishdirs) {
      if (wishDir.startsWith('_')) continue; // Skip archives

      // Check if majority of abbreviation parts match wish slug
      const matches = abbrevParts.filter(part => wishDir.includes(part)).length;
      if (matches >= Math.ceil(abbrevParts.length * 0.7)) {
        return wishDir;
      }
    }

    return null;
  }

  /**
   * Check if task already linked in SESSION-STATE
   */
  isTaskAlreadyLinked(attemptIdPrefix) {
    if (!fs.existsSync(this.sessionStateFile)) {
      return false;
    }

    const content = fs.readFileSync(this.sessionStateFile, 'utf8');
    return content.includes(attemptIdPrefix);
  }

  /**
   * Update SESSION-STATE.md with Forge task linkage
   */
  updateSessionState(metadata, wishSlug) {
    if (!fs.existsSync(this.sessionStateFile)) {
      this.warnings.push(`SESSION-STATE.md not found: ${this.sessionStateFile}`);
      return false;
    }

    let content = fs.readFileSync(this.sessionStateFile, 'utf8');
    const timestamp = new Date().toISOString().replace('T', ' ').replace(/\.\d{3}Z$/, ' UTC');

    // Create new entry
    const entry = `
### Forge Task - ${wishSlug}
**Attempt ID Prefix:** \`${metadata.attemptIdPrefix}\`
**Wish:** ${wishSlug}
**Branch:** ${metadata.fullBranchName}
**Linked:** ${timestamp}
**Status:** active
**Next:** First commit detected - auto-linked
`;

    // Find Active Sessions section and insert after header
    const activeSection = '## ğŸ¯ Active Sessions';
    const insertPos = content.indexOf(activeSection);

    if (insertPos === -1) {
      this.warnings.push('Could not find "## ğŸ¯ Active Sessions" section');
      return false;
    }

    const lineEnd = content.indexOf('\n', insertPos) + 1;
    const insertAfter = content.indexOf('\n', lineEnd) + 1;

    content = content.slice(0, insertAfter) + entry + '\n' + content.slice(insertAfter);

    fs.writeFileSync(this.sessionStateFile, content);
    execSync('git add .genie/SESSION-STATE.md', { stdio: 'pipe' });

    return true;
  }

  /**
   * Run the linking workflow
   */
  async run() {
    this.log('cyan', 'ğŸ§', 'Forge task linking...\n');

    // Check if in Forge worktree
    if (!this.isForgeWorktree()) {
      // Not a Forge worktree, skip silently
      return 0;
    }

    // Get current branch
    const branch = this.getCurrentBranch();
    if (!branch) {
      this.warnings.push('Could not determine current branch');
      return 1;
    }

    // Extract Forge metadata
    const metadata = this.extractForgeMetadata(branch);
    if (!metadata) {
      // Not a Forge branch, skip silently
      return 0;
    }

    this.log('blue', 'â„¹ï¸ ', `Detected Forge branch: ${branch}`);
    this.log('blue', 'â„¹ï¸ ', `Attempt ID prefix: ${metadata.attemptIdPrefix}`);

    // Check if already linked
    if (this.isTaskAlreadyLinked(metadata.attemptIdPrefix)) {
      this.log('green', 'âœ…', 'Task already linked in SESSION-STATE.md');
      return 0;
    }

    // Find matching wish
    const wishSlug = this.findMatchingWish(metadata.taskAbbrev);
    if (!wishSlug) {
      this.log('yellow', 'âš ï¸ ', `Could not find matching wish for: ${metadata.taskAbbrev}`);
      this.warnings.push(`Task abbreviation "${metadata.taskAbbrev}" didn't match any wish`);
      return 1;
    }

    this.log('blue', 'â„¹ï¸ ', `Found matching wish: ${wishSlug}`);

    // Update SESSION-STATE.md
    const linked = this.updateSessionState(metadata, wishSlug);
    if (linked) {
      this.log('green', 'âœ…', `Linked Forge task to wish: ${wishSlug}`);
      this.log('green', 'âœ…', 'Updated SESSION-STATE.md');
      return 0;
    } else {
      this.log('yellow', 'âš ï¸ ', 'Could not update SESSION-STATE.md');
      return 1;
    }
  }
}

// Main
(async () => {
  try {
    const linker = new ForgeTaskLinker();
    const exitCode = await linker.run();
    process.exit(exitCode);
  } catch (e) {
    console.error('âŒ Forge task linking error:', e.message);
    process.exit(2);
  }
})();
```

</details>

### âœ… `.genie/scripts/generate-agent-tree.cjs` (9.4 KB)

<details>
<summary>View new file content</summary>

```markdown
#!/usr/bin/env node

const fs = require('fs');
const path = require('path');

function scanAgents(root) {
  const genieRoot = path.join(root, '.genie');
  const out = { code_agents: [], create_agents: [], code_workflows: [], orchestrators: [], git_workflows: [] };

  function push(filePath, bucket) {
    out[bucket].push({
      name: path.basename(filePath, path.extname(filePath)),
      path: path.relative(root, filePath),
      full_path: filePath,
    });
  }

  // Scan code agents
  const codeAgentsDir = path.join(genieRoot, 'code', 'agents');
  if (fs.existsSync(codeAgentsDir)) {
    for (const f of fs.readdirSync(codeAgentsDir)) {
      if (f.endsWith('.md')) {
        push(path.join(codeAgentsDir, f), 'code_agents');
      } else if (fs.statSync(path.join(codeAgentsDir, f)).isDirectory()) {
        // Check for git/ or wish/ subdirectories
        const agentFile = path.join(codeAgentsDir, f, `${f}.md`);
        if (fs.existsSync(agentFile)) {
          push(agentFile, 'code_agents');
          // Check for workflows subdirectory
          const wfDir = path.join(codeAgentsDir, f, 'workflows');
          if (fs.existsSync(wfDir)) {
            for (const wf of fs.readdirSync(wfDir)) {
              if (wf.endsWith('.md')) push(path.join(wfDir, wf), 'git_workflows');
            }
          }
        }
      }
    }
  }

  // Scan code workflows
  const codeWorkflowsDir = path.join(genieRoot, 'code', 'workflows');
  if (fs.existsSync(codeWorkflowsDir)) {
    for (const f of fs.readdirSync(codeWorkflowsDir)) {
      if (f.endsWith('.md')) push(path.join(codeWorkflowsDir, f), 'code_workflows');
    }
  }

  // Scan code collective
  const codeDir = path.join(genieRoot, 'code');
  if (fs.existsSync(codeDir)) {
    const codeOrch = path.join(codeDir, 'code.md');
    if (fs.existsSync(codeOrch)) out.orchestrators.push({ name: 'code', path: path.relative(root, codeOrch), full_path: codeOrch });
  }

  // Scan create agents
  const createAgentsDir = path.join(genieRoot, 'create', 'agents');
  if (fs.existsSync(createAgentsDir)) {
    for (const f of fs.readdirSync(createAgentsDir)) {
      if (f.endsWith('.md')) push(path.join(createAgentsDir, f), 'create_agents');
    }
  }

  // Scan create collective
  const createDir = path.join(genieRoot, 'create');
  if (fs.existsSync(createDir)) {
    const createOrch = path.join(createDir, 'create.md');
    if (fs.existsSync(createOrch)) out.orchestrators.push({ name: 'create', path: path.relative(root, createOrch), full_path: createOrch });
  }

  return out;
}

function extractDelegations(filePath) {
  try {
    const content = fs.readFileSync(filePath, 'utf8');
    const re = /mcp__genie__run.*?agent=["']([^"']+)["']/gs;
    const set = new Set();
    let m; while ((m = re.exec(content))) set.add(m[1]);
    return Array.from(set);
  } catch { return []; }
}

function generateMermaid(agents) {
  const lines = [];
  lines.push('```mermaid');
  lines.push('graph TB');
  lines.push('    %% Genie Agent Tree');
  lines.push('');
  lines.push('    %% Code Collective');
  lines.push('    CODE[Code Collective]:::orchestrator');
  const codeAgents = [...agents.code_agents].sort((a,b)=>a.name.localeCompare(b.name));
  codeAgents.slice(0,6).forEach((a)=>{ lines.push(`    code_${a.name}[${a.name}]:::code_agent`); lines.push(`    CODE --> code_${a.name}`); });
  if (codeAgents.length > 6) { lines.push(`    more_code[...${codeAgents.length-6} more]:::more`); lines.push('    CODE --> more_code'); }
  if (agents.git_workflows.length) {
    lines.push('');
    lines.push('    %% Git Workflows');
    const git = codeAgents.find((a)=>a.name==='git');
    if (git) { lines.push('    code_git --> git_issue[issue]:::workflow'); lines.push('    code_git --> git_pr[pr]:::workflow'); lines.push('    code_git --> git_report[report]:::workflow'); }
  }
  lines.push('');
  if (agents.code_workflows.length) {
    lines.push('    %% Code Workflows');
    const workflows = [...agents.code_workflows].sort((a,b)=>a.name.localeCompare(b.name));
    workflows.slice(0,4).forEach((a)=>{ lines.push(`    workflow_${a.name}[${a.name}]:::workflow`); lines.push(`    CODE --> workflow_${a.name}`); });
  }
  if (agents.create_agents.length || agents.orchestrators.find(o=>o.name==='create')) {
    lines.push('');
    lines.push('    %% Create Collective');
    lines.push('    CREATE[Create Collective]:::orchestrator');
    const createAgents = [...agents.create_agents].sort((a,b)=>a.name.localeCompare(b.name));
    createAgents.forEach((a)=>{ lines.push(`    create_${a.name}[${a.name}]:::create_agent`); lines.push(`    CREATE --> create_${a.name}`); });
  }
  lines.push('');
  lines.push('    %% Styling');
  lines.push('    classDef orchestrator fill:#fff3e0,stroke:#f57c00,stroke-width:3px');
  lines.push('    classDef code_agent fill:#e8f5e9,stroke:#388e3c,stroke-width:2px');
  lines.push('    classDef create_agent fill:#fce4ec,stroke:#c2185b,stroke-width:2px');
  lines.push('    classDef workflow fill:#fff9c4,stroke:#fbc02d,stroke-width:1px');
  lines.push('    classDef more fill:#f5f5f5,stroke:#9e9e9e,stroke-width:1px,stroke-dasharray: 5 5');
  lines.push('```');
  return lines.join('\n');
}

function generateMarkdownTree(agents) {
  const lines = [];
  lines.push('## Agent Tree');
  lines.push('');
  lines.push('**Auto-generated** from `.genie/` folder structure');
  lines.push('');
  const total = agents.code_agents.length + agents.git_workflows.length + agents.create_agents.length + agents.code_workflows.length + agents.orchestrators.length;
  lines.push('**Summary:**');
  lines.push(`- Code agents: ${agents.code_agents.length}`);
  lines.push(`- Code workflows: ${agents.code_workflows.length}`);
  lines.push(`- Git workflows: ${agents.git_workflows.length}`);
  lines.push(`- Create agents: ${agents.create_agents.length}`);
  lines.push(`- Orchestrators: ${agents.orchestrators.length}`);
  lines.push(`- **Total: ${total} agents**`);
  lines.push('');
  lines.push('### Code Collective');
  lines.push('');
  lines.push('**Orchestrator:** `code`');
  lines.push('');
  lines.push('**Agents:**');
  for (const a of [...agents.code_agents].sort((x,y)=>x.name.localeCompare(y.name))) {
    const dels = extractDelegations(a.full_path);
    lines.push(dels.length ? `- **${a.name}** â†’ ${dels.map((d)=>'`'+d+'`').join(', ')}` : `- **${a.name}**`);
  }
  if (agents.code_workflows.length) {
    lines.push('');
    lines.push('**Workflows:**');
    for (const a of [...agents.code_workflows].sort((x,y)=>x.name.localeCompare(y.name))) {
      lines.push(`- **${a.name}**`);
    }
  }
  if (agents.git_workflows.length) {
    lines.push('');
    lines.push('**Git workflows:** `issue`, `pr`, `report`');
  }
  if (agents.create_agents.length) {
    lines.push('');
    lines.push('### Create Collective');
    lines.push('');
    lines.push('**Orchestrator:** `create`');
    lines.push('');
    lines.push('**Agents:**');
    for (const a of [...agents.create_agents].sort((x,y)=>x.name.localeCompare(y.name))) {
      lines.push(`- **${a.name}**`);
    }
  }
  return lines.join('\n');
}

function updateBetweenMarkers(filePath, startMarker, endMarker, newContent) {
  if (!fs.existsSync(filePath)) { console.warn(`âš ï¸  File not found: ${filePath}`); return false; }
  const content = fs.readFileSync(filePath, 'utf8');
  const startIdx = content.indexOf(startMarker);
  const endIdx = content.indexOf(endMarker);
  if (startIdx === -1 || endIdx === -1 || endIdx <= startIdx) {
    console.warn(`âš ï¸  Markers not found in ${path.relative(process.cwd(), filePath)}`);
    return false;
  }
  const before = content.slice(0, startIdx + startMarker.length) + '\n';
  const after = '\n' + content.slice(endIdx);
  fs.writeFileSync(filePath, before + newContent + after);
  return true;
}

function main() {
  const repoRoot = path.join(__dirname, '..', '..');
  console.log('ğŸ” Scanning .genie/ structure...');
  const agents = scanAgents(repoRoot);
  const total = agents.code_agents.length + agents.code_workflows.length + agents.git_workflows.length + agents.create_agents.length + agents.orchestrators.length;
  console.log(`   Found ${total} agents total`);
  console.log(`   - Code agents: ${agents.code_agents.length}`);
  console.log(`   - Code workflows: ${agents.code_workflows.length}`);
  console.log(`   - Git workflows: ${agents.git_workflows.length}`);
  console.log(`   - Create agents: ${agents.create_agents.length}`);
  console.log(`   - Orchestrators: ${agents.orchestrators.length}`);

  console.log('\nğŸŒ² Generating Mermaid diagram...');
  const mermaid = generateMermaid(agents);
  console.log('ğŸ“ Generating markdown tree...');
  const mdTree = generateMarkdownTree(agents);

  const readme = path.join(repoRoot, 'README.md');
  console.log(`\nğŸ“„ Updating ${path.relative(repoRoot, readme)}...`);
  const ok1 = updateBetweenMarkers(readme, '<!-- AGENT_TREE_START -->', '<!-- AGENT_TREE_END -->', mermaid);
  console.log(ok1 ? '   âœ… Mermaid chart updated' : '   âš ï¸  Could not update Mermaid chart (markers missing)');

  const genieReadme = path.join(repoRoot, '.genie', 'README.md');
  console.log(`\nğŸ“„ Updating ${path.relative(repoRoot, genieReadme)}...`);
  const ok2 = updateBetweenMarkers(genieReadme, '<!-- NEURAL_TREE_START -->', '<!-- NEURAL_TREE_END -->', mdTree);
  console.log(ok2 ? '   âœ… Markdown tree updated' : '   âš ï¸  Could not update markdown tree (markers missing)');

  console.log('\nâœ¨ Agent agent tree generation complete!');
  console.log('   - README.md: Mermaid flowchart');
  console.log('   - .genie/README.md: Detailed markdown tree');
}

main();
```

</details>

### âœ… `.genie/scripts/genie-workflow-parser.cjs` (6.8 KB)

<details>
<summary>View new file content</summary>

```markdown
#!/usr/bin/env node

/**
 * Genie Workflow Output Parser
 *
 * Extracts structured data from Genie agent sessions for use in git hooks.
 *
 * Usage:
 *   node genie-workflow-parser.js <sessionId> <outputFormat>
 *
 * Formats:
 *   - json: Structured JSON output
 *   - exit-code: Returns 0/1/2 based on validation results
 *   - markdown: Markdown summary
 *   - validation: Validation results only
 *
 * Example:
 *   const result = require('./genie-workflow-parser.js')
 *   const output = result.parseSession('abc123', 'json')
 */

const fs = require('fs');
const path = require('path');

const REPO_ROOT = path.join(__dirname, '..');
const LOGS_DIR = path.join(REPO_ROOT, '.genie', 'state', 'agents', 'logs');
const SESSIONS_FILE = path.join(REPO_ROOT, '.genie', 'state', 'agents', 'sessions.json');

class GenieworkflowParser {
  constructor() {
    this.output = [];
    this.errors = [];
    this.warnings = [];
    this.validations = {};
    this.exitCode = 0;
  }

  /**
   * Find log file for session
   */
  findLogFile(sessionId) {
    if (!fs.existsSync(LOGS_DIR)) return null;

    // Try direct lookup from sessions file first
    if (fs.existsSync(SESSIONS_FILE)) {
      try {
        const data = JSON.parse(fs.readFileSync(SESSIONS_FILE, 'utf8'));
        const sessions = data.sessions || {};
        const entry = Object.values(sessions).find(s => s.sessionId === sessionId);
        if (entry && entry.logFile) {
          const logPath = entry.logFile.startsWith('/')
            ? entry.logFile
            : path.join(REPO_ROOT, entry.logFile);
          if (fs.existsSync(logPath)) return logPath;
        }
      } catch {}
    }

    // Fallback: find by pattern
    const files = fs.readdirSync(LOGS_DIR);
    const matching = files.find(f => f.includes(sessionId.substring(0, 8)));
    return matching ? path.join(LOGS_DIR, matching) : null;
  }

  /**
   * Parse JSONL log file
   */
  parseLogFile(logPath) {
    if (!fs.existsSync(logPath)) {
      this.errors.push(`Log file not found: ${logPath}`);
      return null;
    }

    const content = fs.readFileSync(logPath, 'utf8');
    const lines = content.split('\n').filter(l => l.trim());

    const events = [];
    const messages = [];

    for (const line of lines) {
      try {
        const event = JSON.parse(line);
        events.push(event);

        // Extract assistant messages
        if (event.type === 'item.completed' && event.item?.item_type === 'assistant_message') {
          messages.push(event.item.text);
        }
      } catch {
        // Skip unparseable lines
      }
    }

    return { events, messages, fullText: messages.join('\n') };
  }

  /**
   * Extract validation structure from workflow output
   *
   * Genie workflows typically produce structured output like:
   * ```markdown
   * ## Validation Results
   *
   * ### âœ… Passed
   * - Rule 1 passed
   * - Rule 2 passed
   *
   * ### âš ï¸ Warnings (2)
   * 1. Warning 1
   * 2. Warning 2
   *
   * ### âŒ Errors (1)
   * 1. Error 1
   * ```
   */
  extractValidationStructure(fullText) {
    const result = {
      passed: [],
      warnings: [],
      errors: [],
      hasBlockingErrors: false,
      hasWarnings: false
    };

    // Extract passed items
    const passedMatch = fullText.match(/###\s*âœ…\s*Passed[\s\S]*?(?=###|$)/);
    if (passedMatch) {
      const items = passedMatch[0].match(/[-*]\s+(.+)/g) || [];
      result.passed = items.map(item => item.replace(/^[-*]\s+/, '').trim());
    }

    // Extract warnings
    const warningsMatch = fullText.match(/###\s*âš ï¸\s*Warnings?\s*\((\d+)\)[\s\S]*?(?=###|$)/);
    if (warningsMatch) {
      const count = parseInt(warningsMatch[1]);
      if (count > 0) {
        result.hasWarnings = true;
        const items = warningsMatch[0].match(/^\d+\.\s+(.+?)(?=\n\d+\.|$)/gm) || [];
        result.warnings = items.map(item => item.replace(/^\d+\.\s+/, '').trim());
      }
    }

    // Extract errors
    const errorsMatch = fullText.match(/###\s*âŒ\s*(?:Blocking\s+)?Issues?\s*\((\d+)\)[\s\S]*?(?=###|$)/);
    if (errorsMatch) {
      const count = parseInt(errorsMatch[1]);
      if (count > 0) {
        result.hasBlockingErrors = true;
        const items = errorsMatch[0].match(/^\d+\.\s+(.+?)(?=\n\d+\.|$)/gm) || [];
        result.errors = items.map(item => item.replace(/^\d+\.\s+/, '').trim());
      }
    }

    return result;
  }

  /**
   * Parse session and extract validation data
   */
  parseSession(sessionId, format = 'json') {
    const logPath = this.findLogFile(sessionId);
    if (!logPath) {
      this.errors.push(`Session not found: ${sessionId}`);
      return this.formatOutput(format);
    }

    const parsed = this.parseLogFile(logPath);
    if (!parsed) {
      return this.formatOutput(format);
    }

    // Extract validation structure
    this.validations = this.extractValidationStructure(parsed.fullText);

    // Determine exit code
    if (this.validations.hasBlockingErrors) {
      this.exitCode = 2;
    } else if (this.validations.hasWarnings) {
      this.exitCode = 1;
    } else {
      this.exitCode = 0;
    }

    return this.formatOutput(format, parsed.fullText);
  }

  /**
   * Format output based on requested format
   */
  formatOutput(format, fullText = '') {
    switch (format) {
      case 'json':
        return JSON.stringify({
          exitCode: this.exitCode,
          validations: this.validations,
          errors: this.errors,
          warnings: this.warnings
        }, null, 2);

      case 'exit-code':
        return this.exitCode.toString();

      case 'validation':
        return JSON.stringify(this.validations, null, 2);

      case 'markdown':
        return fullText;

      case 'summary':
        return {
          exitCode: this.exitCode,
          passed: this.validations.passed?.length || 0,
          warnings: this.validations.warnings?.length || 0,
          errors: this.validations.errors?.length || 0,
          blocking: this.validations.hasBlockingErrors
        };

      default:
        return JSON.stringify({
          exitCode: this.exitCode,
          validations: this.validations
        }, null, 2);
    }
  }
}

// Module export
if (require.main === module) {
  // CLI usage: node script.js <sessionId> <format>
  const sessionId = process.argv[2];
  const format = process.argv[3] || 'json';

  if (!sessionId) {
    console.error('Usage: genie-workflow-parser.js <sessionId> [format]');
    console.error('Formats: json, exit-code, markdown, validation, summary');
    process.exit(1);
  }

  const parser = new GenieworkflowParser();
  const output = parser.parseSession(sessionId, format);

  if (format === 'exit-code') {
    process.stdout.write(output);
    process.exit(parseInt(output));
  } else if (format === 'summary' && typeof output === 'object') {
    console.log(JSON.stringify(output, null, 2));
  } else {
    console.log(output);
  }
} else {
  // Module export
  module.exports = GenieworkflowParser;
}
```

</details>

### âœ… `.genie/scripts/hooks/pre-commit.cjs` (8.8 KB)

<details>
<summary>View new file content</summary>

```markdown
#!/usr/bin/env node

const { spawnSync, execSync } = require('child_process');
const path = require('path');

// Get git root directory (works from .git/hooks/)
const gitRoot = execSync('git rev-parse --show-toplevel', { encoding: 'utf8' }).trim();

function run(script) {
  const p = path.join(gitRoot, '.genie', 'scripts', script);
  const res = spawnSync('node', [p], { stdio: 'inherit' });
  return res.status || 0;
}

// TODO: Re-enable when `genie run` CLI is stable (currently causes instability in hooks)
// function runGenie(agent, prompt) {
//   // Run Genie workflow and capture session ID + wait for completion
//   const { execSync } = require('child_process');
//   const fs = require('fs');
//
//   try {
//     const genieCliPath = path.join(gitRoot, '.genie', 'cli', 'dist', 'genie-cli.js');
//     if (!fs.existsSync(genieCliPath)) {
//       return { sessionId: null, success: true, message: 'Genie CLI not built (skipping workflow)' };
//     }
//
//     console.log(`Running Genie workflow: ${agent}...`);
//
//     // Start workflow (fire and forget, non-blocking)
//     const spawn = require('child_process').spawn;
//     const proc = spawn('node', [genieCliPath, 'run', agent, prompt], {
//       cwd: gitRoot,
//       stdio: 'ignore',
//       detached: true
//     });
//     proc.unref();
//
//     // Return success - workflow runs in background
//     return { sessionId: null, success: true, message: `Workflow ${agent} started (runs in background)` };
//   } catch (e) {
//     console.log(`âš ï¸  Could not run workflow: ${e.message}`);
//     return { sessionId: null, success: true, message: 'Workflow skipped' };
//   }
// }

// Check if commit only contains files that don't require full hook validation
function shouldSkipHooks() {
  try {
    const stagedFiles = execSync('git diff --cached --name-only', { encoding: 'utf8' }).trim().split('\n').filter(Boolean);
    if (stagedFiles.length === 0) return false;

    // ==============================================================================
    // SKIP PATTERNS (expand this list as needed for performance optimization)
    // ==============================================================================
    // Pattern 1: .genie/wishes/*.md - Wish documents that don't affect codebase
    // Pattern 2: [FUTURE] Documentation-only commits
    // Pattern 3: [FUTURE] Test fixtures or mock data
    // ==============================================================================

    const skipPatterns = [
      // Pattern 1: Wish files only
      (file) => file.startsWith('.genie/wishes/') && file.endsWith('.md'),

      // Add more patterns here as needed:
      // (file) => file.startsWith('.genie/docs/') && file.endsWith('.md'),
      // (file) => file.startsWith('test/fixtures/') && file.endsWith('.json'),
    ];

    // Skip hooks if ALL staged files match at least one skip pattern
    const allFilesSkippable = stagedFiles.every(file =>
      skipPatterns.some(pattern => pattern(file))
    );

    return allFilesSkippable;
  } catch (e) {
    return false; // On error, run hooks normally
  }
}

// Timing utility
function timeExecution(label, fn) {
  const start = Date.now();
  const result = fn();
  const duration = Date.now() - start;
  console.log(`  â±ï¸  ${label}: ${duration}ms`);
  return result;
}

function main() {
  const totalStart = Date.now();
  console.log('## Pre-Commit');

  // Early exit for forge worktrees (total isolation, full performance)
  try {
    const gitDir = execSync('git rev-parse --git-dir', { encoding: 'utf8' }).trim();
    const branch = execSync('git rev-parse --abbrev-ref HEAD', { encoding: 'utf8' }).trim();
    const isWorktree = gitDir.includes('/worktrees/');
    const isForgeBranch = branch.startsWith('forge/');

    if (isForgeBranch || isWorktree) {
      console.log('ğŸ”§ Forge worktree detected - skipping ALL hooks (full performance mode)');
      console.log(`   Branch: ${branch}`);
      console.log('- Result: âœ… Pre-commit validations skipped (forge isolation)');
      process.exit(0);
    }
  } catch (e) {
    // Continue with normal hooks on error
  }

  // Early exit for .genie/wishes/*.md only commits
  if (shouldSkipHooks()) {
    console.log('âœ¨ Fast-path: Only wish files detected, skipping hooks');
    console.log('- Result: âœ… Pre-commit validations skipped (wish-only commit)');
    process.exit(0);
  }

  let exitCode = 0;
  const validations = [
    'validate-user-files-not-committed.cjs',
    'validate-cross-references.cjs',
    'forge-task-link.cjs',  // Auto-link Forge tasks to wishes on first commit
    'validate-mcp-build.cjs',  // Ensure MCP dist files are in sync with source
  ];

  // Security validation (blocking)
  console.log('ğŸ” Checking for secrets in staged files...');
  const checkSecretsPath = path.join(gitRoot, '.genie', 'scripts', 'helpers', 'check-secrets.js');
  const secretsCheckCode = timeExecution('Secret detection', () => {
    const secretsCheck = spawnSync('node', [checkSecretsPath, '--staged'], { stdio: 'inherit' });
    return secretsCheck.status || 0;
  });
  if (secretsCheckCode !== 0) {
    exitCode = 1;
  }

  // Path validation (blocking)
  console.log('ğŸ”— Validating file path references...');
  const validatePathsPath = path.join(gitRoot, '.genie', 'scripts', 'helpers', 'validate-paths.js');
  const pathsCheckCode = timeExecution('Path validation', () => {
    const pathsCheck = spawnSync('node', [validatePathsPath, '--staged'], { stdio: 'inherit' });
    return pathsCheck.status || 0;
  });
  if (pathsCheckCode !== 0) {
    exitCode = 1;
  }

  // Amendment #7: Git is source of truth - no auto-metadata generation
  // Disabled: update-genie-markdown-metadata.cjs (timestamps/versions duplicate git data)

  // Run worktree access prevention check (bash script)
  console.log('ğŸ” Checking for Forge worktree violations...');
  const worktreeCheckPath = path.join(gitRoot, '.genie', 'scripts', 'prevent-worktree-access.sh');
  const worktreeCheckCode = timeExecution('Worktree validation', () => {
    const worktreeCheck = spawnSync('bash', [worktreeCheckPath], { stdio: 'inherit' });
    return worktreeCheck.status || 0;
  });
  if (worktreeCheckCode !== 0) {
    exitCode = 1;
  }

  for (const v of validations) {
    const code = timeExecution(v.replace('.cjs', ''), () => run(v));
    if (code !== 0) exitCode = 1;
  }

  // Amendment #7: Removed generate-workspace-summary.cjs (redundant with hand-curated knowledge graph in AGENTS.md)
  // Removed migrate-qa-from-bugs.cjs (generated useless TBD files in wrong location, scenarios-from-bugs.md is sufficient)

  // Generate token usage and quality summary (non-blocking)
  try {
    timeExecution('Token counting', () => {
      spawnSync('node', [path.join(gitRoot, '.genie', 'scripts', 'token-efficiency', 'count-tokens.cjs')], { stdio: 'inherit' });
      return 0;
    });
  } catch (e) {
    console.warn('âš ï¸  Token usage script failed (non-blocking)');
  }
  try {
    timeExecution('Quality gate check', () => {
      spawnSync('node', [path.join(gitRoot, '.genie', 'scripts', 'token-efficiency', 'quality-gate.cjs')], { stdio: 'inherit' });
      return 0;
    });
  } catch (e) {
    console.warn('âš ï¸  Token quality gate error (non-blocking)');
  }

  // TODO: Re-enable Genie background advisory when `genie run` CLI is stable
  // Background advisory currently disabled for performance and reliability
  // Future: Async learning/analysis of commit patterns, wish alignment, etc.
  // const workflow = runGenie('neurons/git/commit-advisory', 'Pre-commit validation');
  // if (workflow.message) console.log(`- Note: ${workflow.message}`);

  // Commit message suggestion (non-blocking, advisory only)
  // Generates conventional commit message from staged diff
  // Disabled for now - enable when genie run is stable in hooks
  // try {
  //   const suggestion = execSync('genie run commit-suggester --raw --quiet', { encoding: 'utf8', cwd: gitRoot }).trim();
  //   if (suggestion) {
  //     const suggestedMsgPath = path.join(gitRoot, '.git', 'SUGGESTED_COMMIT');
  //     require('fs').writeFileSync(suggestedMsgPath, suggestion);
  //     console.log('ğŸ’¡ Commit message suggestion saved to .git/SUGGESTED_COMMIT');
  //     console.log('   Use: git commit -F .git/SUGGESTED_COMMIT');
  //   }
  // } catch (e) {
  //   // Silently skip if genie run fails (non-blocking)
  // }

  // Token-efficient summary
  const totalDuration = Date.now() - totalStart;
  if (exitCode === 0) {
    console.log('- Result: âœ… Pre-commit validations passed');
    console.log('- Reinforcer: Save tokens â€” keep outputs concise');
  } else {
    console.log('- Result: âŒ Some validations failed');
    console.log('- Next: Fix issues above and retry commit');
    console.log('- Reinforcer: Commit small and often; attach evidence paths when relevant');
  }
  console.log(`â±ï¸  Total pre-commit time: ${totalDuration}ms`);
  process.exit(exitCode);
}

main();
```

</details>

### âœ… `.genie/scripts/hooks/pre-push.cjs` (7.4 KB)

<details>
<summary>View new file content</summary>

```markdown
#!/usr/bin/env node

const { spawnSync, execSync } = require('child_process');
const path = require('path');
const fs = require('fs');

function getWorktreeRoot() {
  try {
    // Get the top-level directory of the current worktree
    const result = execSync('git rev-parse --show-toplevel', {
      encoding: 'utf8',
      stdio: ['pipe', 'pipe', 'pipe']
    }).trim();
    return result;
  } catch (e) {
    // Fallback to current directory if git command fails
    return process.cwd();
  }
}

function runNodeScript(script, args = []) {
  const worktreeRoot = getWorktreeRoot();
  const p = path.join(worktreeRoot, '.genie', 'scripts', script);
  const res = spawnSync('node', [p, ...args], {
    stdio: 'inherit',
    cwd: worktreeRoot  // Run from worktree root, not main repo
  });
  return res.status || 0;
}

function getCurrentBranch() {
  try {
    // Try to get branch from current working directory context
    // This works correctly in worktrees when git push is executed
    const result = execSync('git rev-parse --abbrev-ref HEAD', {
      encoding: 'utf8',
      stdio: ['pipe', 'pipe', 'pipe']
    }).trim();

    return result;
  } catch (e) {
    // Fallback: try reading HEAD file directly
    try {
      const gitDir = process.env.GIT_DIR || path.join(__dirname, '..');
      const headFile = path.join(gitDir, 'HEAD');

      if (fs.existsSync(headFile)) {
        const head = fs.readFileSync(headFile, 'utf8').trim();
        if (head.startsWith('ref: refs/heads/')) {
          return head.replace('ref: refs/heads/', '');
        }
      }
    } catch {}

    return '';
  }
}

function autoSyncWithRemote(branch) {
  // Auto-sync with remote to prevent rejection due to automated commits (like RC version bumps)
  if (process.env.GENIE_SKIP_AUTO_SYNC) {
    console.log('â­ï¸  Auto-sync skipped (GENIE_SKIP_AUTO_SYNC set)');
    return false; // No rebase happened
  }

  console.log('ğŸ”„ Auto-syncing with remote...');

  try {
    // Fetch latest from remote
    execSync(`git fetch origin ${branch}`, {
      encoding: 'utf8',
      stdio: ['pipe', 'pipe', 'pipe']
    });

    // Check if remote is ahead
    const localCommit = execSync('git rev-parse HEAD', {
      encoding: 'utf8',
      stdio: ['pipe', 'pipe', 'pipe']
    }).trim();

    const remoteCommit = execSync(`git rev-parse origin/${branch}`, {
      encoding: 'utf8',
      stdio: ['pipe', 'pipe', 'pipe']
    }).trim();

    if (localCommit === remoteCommit) {
      console.log('âœ… Already in sync with remote');
      return false; // No rebase needed
    }

    // Check if we're behind
    const behindCount = execSync(`git rev-list --count HEAD..origin/${branch}`, {
      encoding: 'utf8',
      stdio: ['pipe', 'pipe', 'pipe']
    }).trim();

    if (parseInt(behindCount) > 0) {
      console.log(`ğŸ“¥ Remote is ${behindCount} commit(s) ahead, rebasing...`);

      // Rebase on remote
      const rebaseResult = spawnSync('git', ['rebase', `origin/${branch}`], {
        stdio: 'inherit'
      });

      if (rebaseResult.status !== 0) {
        console.error('âŒ Auto-rebase failed - please resolve conflicts manually');
        console.error('   Run: git rebase --abort && git pull --rebase');
        process.exit(1);
      }

      console.log('âœ… Successfully rebased on remote changes');
      return true; // Rebase happened, need to retry push
    } else {
      console.log('âœ… Local is ahead of remote');
      return false; // No rebase needed
    }
  } catch (e) {
    console.warn(`âš ï¸  Auto-sync failed: ${e.message}`);
    console.warn('   Continuing with push (may be rejected if remote changed)');
    return false; // Error, let original push handle it
  }
}

function main() {
  console.log('ğŸ§ Genie pre-push hook');
  const currentBranch = getCurrentBranch();
  const isForgeBranch = currentBranch.startsWith('forge/');
  const isFeatBranch = currentBranch.startsWith('feat/');
  const isWorkInProgress = isForgeBranch || isFeatBranch;

  console.log(`ğŸ“ Detected branch: ${currentBranch}`);

  // Early exit for forge worktrees (total isolation, full performance)
  try {
    const gitDir = execSync('git rev-parse --git-dir', { encoding: 'utf8' }).trim();
    const isWorktree = gitDir.includes('/worktrees/');

    if (isForgeBranch || isWorktree) {
      console.log('ğŸ”§ Forge worktree detected - skipping ALL hooks (full performance mode)');
      console.log('- Result: âœ… Pre-push validations skipped (forge isolation)');
      process.exit(0);
    }
  } catch (e) {
    // Continue with normal hooks on error
  }

  // Step 0: Auto-sync with remote (prevents rejection from automated commits)
  const didRebase = autoSyncWithRemote(currentBranch);

  // Step 1: tests (skip if GENIE_SKIP_TESTS is set)
  if (process.env.GENIE_SKIP_TESTS) {
    console.warn('âš ï¸  Tests skipped (GENIE_SKIP_TESTS set)');
  } else {
    const testsCode = runNodeScript('run-tests.cjs');
    if (testsCode !== 0) {
      console.error('âŒ Pre-push blocked - tests failed');
      process.exit(1);
    }
  }
  // Step 2: commit advisory (validates traceability)
  let advisoryCode = 0;
  if (process.env.GENIE_ALLOW_MAIN_PUSH) {
    console.warn('âš ï¸  Commit advisory skipped (GENIE_ALLOW_MAIN_PUSH set)');
  } else {
    advisoryCode = runNodeScript('commit-advisory.cjs');

    // Block on main branch, warn on dev/feature branches
    if (advisoryCode === 2) {
      if (currentBranch === 'main' || currentBranch === 'master') {
        console.error('âŒ Pre-push blocked - fix commit validation errors before pushing to main');
        console.error('    See output above for details');
        process.exit(1);
      } else {
        console.warn('âš ï¸  Commit validation issues detected (blocking at PR approval)');
        console.warn('    See output above for details');
      }
    }
    if (advisoryCode === 1 && !process.env.GENIE_SKIP_WISH_CHECK) {
      console.warn('âš ï¸  Commit advisory warnings (will be checked at PR approval)');
    }
  }
  // Step 3: update changelog (non-blocking)
  const clCode = runNodeScript('update-changelog.cjs');
  if (clCode !== 0) {
    console.warn('âš ï¸  CHANGELOG update failed (non-blocking)');
  }

  // Step 4: change-reviewer agent (non-blocking, advisory only)
  // Quick sanity check: security issues, large changes, missing tests
  // Disabled for now - enable when genie run is stable in hooks
  // try {
  //   console.log('ğŸ” Running quick change review...');
  //   const reviewResult = execSync('genie run change-reviewer --quiet', {
  //     encoding: 'utf8',
  //     cwd: getWorktreeRoot(),
  //     stdio: 'inherit'
  //   });
  //   // Advisory only - never blocks (always exit 0)
  // } catch (e) {
  //   // Silently skip if genie run fails (non-blocking)
  // }

  console.log('âœ… Pre-push hooks passed');

  // If we rebased, automatically retry the push
  if (didRebase && !process.env.GENIE_AUTO_PUSH_RETRY) {
    console.log('ğŸ”„ Auto-retrying push after rebase...');

    // Set env var to prevent infinite recursion
    process.env.GENIE_AUTO_PUSH_RETRY = '1';

    try {
      // Retry the push (this will trigger hooks again, but didRebase will be false)
      execSync(`git push origin ${currentBranch}`, {
        stdio: 'inherit'
      });

      console.log('\x1b[32mâœ… Push succeeded after auto-rebase\x1b[0m');
      process.exit(0); // Success, tell original command to abort
    } catch (e) {
      console.error('âŒ Auto-retry push failed');
      process.exit(1);
    }
  }
}

main();
```

</details>

### âœ… `.genie/scripts/hooks/prepare-commit-msg` (1.8 KB)

<details>
<summary>View new file content</summary>

```markdown
#!/usr/bin/env python3
"""
Prepare-commit-msg hook: Add co-author attribution to commits.

Every commit by Genie should credit the Automagik Genie LLM as co-author.
This hook automatically appends the co-author line if not already present.

Exit codes:
    0 - Hook passed, commit message prepared
    1 - Hook failed, abort commit
"""

import sys
import os
from pathlib import Path


def main():
    # Undocumented escape hatch: disable co-author attribution
    if os.environ.get('GENIE_DISABLE_COAUTHOR') == '1':
        sys.exit(0)

    commit_msg_file = sys.argv[1] if len(sys.argv) > 1 else None

    if not commit_msg_file or not Path(commit_msg_file).exists():
        sys.exit(0)  # No message file, nothing to do

    msg_path = Path(commit_msg_file)
    content = msg_path.read_text()

    # This is Genie's identity - hardcoded by design
    target_name = "Automagik Genie ğŸ§"
    target_email = "genie@namastex.ai"
    normalized_line = f"Co-authored-by: {target_name} <{target_email}>"

    lines = content.splitlines()
    updated = False
    found_genie = False

    for i, line in enumerate(lines):
        if line.strip().lower().startswith("co-authored-by:") and target_name in line:
            found_genie = True
            if line.strip() != normalized_line:
                lines[i] = normalized_line
                updated = True

    if not found_genie:
        # Ensure a trailing blank line, then append normalized co-author line
        if lines and lines[-1].strip() != "":
            lines.append("")
        lines.append(normalized_line)
        updated = True

    if updated:
        # Preserve final newline
        msg = "\n".join(lines)
        if not msg.endswith("\n"):
            msg += "\n"
        msg_path.write_text(msg)
    sys.exit(0)


if __name__ == "__main__":
    main()
```

</details>

### âœ… `.genie/scripts/hooks/README.md` (2.8 KB)

<details>
<summary>View new file content</summary>

```markdown
# Genie Git Hooks System

**Purpose:** Enforce quality gates, traceability, and token efficiency at commit and push time.

**Architecture:** Centralized orchestrators (pre-commit, pre-push) call modular validation scripts.

---

## ğŸ“‚ Hook Files (Symlinked from `.git/hooks/`)

### 1. `pre-commit.cjs`
**Trigger:** Before every `git commit`
**Purpose:** Fast validation before commit is created
**Exit Code:** 0 (pass) | 1 (fail)

**Execution Flow:**
```
1. Fast-path check (skip if only wish files changed)
2. Secret detection (blocking, prevents credential leaks)
3. Worktree validation (prevent editing Forge worktrees)
4. User file validation (no personal files committed)
5. Cross-reference validation (all @ references valid)
6. Forge task linking (auto-link wishes to Forge tasks)
7. MCP build validation (ensure dist files match source)
8. Token counting (non-blocking, reports usage)
9. Quality gate (non-blocking, warns on bloat)
```

**Performance:**
- Fast-path: <50ms (wish-only commits)
- Full path: ~550ms (all validations)

**Environment Variables:**
- None (runs always)

**Files Called:**
- `helpers/check-secrets.js`
- `prevent-worktree-access.sh` (bash)
- `validate-user-files-not-committed.cjs`
- `validate-cross-references.cjs`
- `forge-task-link.cjs`
- `validate-mcp-build.cjs`
- `token-efficiency/count-tokens.cjs`
- `token-efficiency/quality-gate.cjs`

---

### 2. `pre-push.cjs`
**Trigger:** Before every `git push`
**Purpose:** Comprehensive validation before code leaves local machine
**Exit Code:** 0 (pass) | 1 (warn) | 2 (block)

**Execution Flow:**
```
1. Auto-sync with remote (rebase if behind)
2. Run full test suite (genie-cli + session-service)
3. Commit advisory (traceability check)
4. Update changelog (non-blocking)
```

**Environment Variables:**
- `GENIE_SKIP_TESTS=1` - Skip test suite
- `GENIE_ALLOW_MAIN_PUSH=1` - Allow push to main without warnings
- `GENIE_SKIP_WISH_CHECK=1` - Skip wish traceability warnings
- `GENIE_SKIP_AUTO_SYNC=1` - Skip auto-rebase

---

## ğŸ” Validation Scripts (Called by Hooks)

### `commit-advisory.cjs`
**Purpose:** Validate commit traceability and conventional commit types
**Hook:** pre-push
**Blocking:** YES (on main) | WARN (on feature branches)

**EXEMPT COMMIT TYPES** (no wish/issue required):
- `docs:` - Documentation updates
- `style:` - Formatting, whitespace
- `refactor:` - Code restructuring (no behavior change)
- `perf:` - Performance improvements
- `chore:` - Maintenance, dependencies, configs
- `build:` - Build system, CI/CD
- `test:` - Test-only changes
- `ci:` - CI/CD configuration

**FEATURE COMMIT TYPES** (require wish or GitHub issue):
- `feat:` - New features
- `fix:` - Bug fixes (MUST have GitHub issue)
- Untyped commits (treated as feature work)

---

See full documentation at `.genie/scripts/hooks/HOOKS_REFERENCE.md` (to be created with complete details).
```

</details>

### âœ… `.genie/scripts/install-hooks.cjs` (7.2 KB)

<details>
<summary>View new file content</summary>

```markdown
#!/usr/bin/env node
/**
 * Install git hooks - Advanced feature, opt-in only
 *
 * Usage: node install-hooks.cjs <project-dir> <package-root>
 *
 * Arguments:
 *   project-dir   - User's project directory (where .git is located)
 *   package-root  - Genie package installation directory (where hooks templates are)
 *
 * Warning: This modifies your .git/hooks/ directory.
 * Only install if you understand what git hooks do.
 *
 * Hooks installed:
 * - pre-commit: Validates commits (worktree access, cross-refs, token efficiency)
 * - pre-push: Runs tests and validations before push
 * - prepare-commit-msg: Adds Genie co-author attribution
 */

const fs = require('fs');
const path = require('path');

const GREEN = '\x1b[32m';
const RED = '\x1b[31m';
const YELLOW = '\x1b[33m';
const BLUE = '\x1b[34m';
const RESET = '\x1b[0m';

/**
 * Install git hooks with proper error handling and user feedback
 */
function installGitHooks() {
  console.log(`${BLUE}ğŸ§ Genie Git Hooks Installer${RESET}`);
  console.log('');

  // Get directories from command-line arguments
  const projectDir = process.argv[2] || process.cwd();
  const packageRoot = process.argv[3] || __dirname;

  const gitDir = path.join(projectDir, '.git');
  const hooksSourceDir = path.join(packageRoot, '.genie', 'scripts', 'hooks');

  // Check if we're in a git repository
  if (!fs.existsSync(gitDir)) {
    console.error(`${RED}âœ— Error: Not a git repository${RESET}`);
    console.log(`  Project dir: ${projectDir}`);
    console.log('  Run this command from the root of your Genie project.');
    process.exit(1);
  }

  // Check if .git is a file (worktree) or directory (main repo)
  const gitDirStats = fs.statSync(gitDir);
  let gitHooksDir;
  let isWorktree = false;

  if (gitDirStats.isFile()) {
    // Worktree: read the gitdir path from .git file
    isWorktree = true;
    const gitDirContent = fs.readFileSync(gitDir, 'utf8');
    const match = gitDirContent.match(/gitdir:\s*(.+)/);
    if (match) {
      const worktreeGitDir = path.resolve(path.dirname(gitDir), match[1].trim());
      // For worktrees, hooks are in the main .git/hooks directory
      const mainGitDir = worktreeGitDir.replace(/\/worktrees\/[^/]+$/, '');
      gitHooksDir = path.join(mainGitDir, 'hooks');
    }
  } else {
    // Main repository
    gitHooksDir = path.join(gitDir, 'hooks');
  }

  if (!gitHooksDir || !fs.existsSync(gitHooksDir)) {
    console.error(`${RED}âœ— Error: Cannot find .git/hooks directory${RESET}`);
    process.exit(1);
  }

  // Check if hook templates exist
  if (!fs.existsSync(hooksSourceDir)) {
    console.error(`${RED}âœ— Error: Hook templates not found${RESET}`);
    console.log(`  Expected: ${hooksSourceDir}`);
    console.log(`  Package root: ${packageRoot}`);
    process.exit(1);
  }

  console.log(`${YELLOW}âš   Advanced Feature Warning${RESET}`);
  console.log('');
  console.log('  Git hooks will modify your commit/push workflow:');
  console.log('  - pre-commit: Validates worktree access, cross-refs, token usage');
  console.log('  - pre-push: Runs tests before pushing');
  console.log('  - prepare-commit-msg: Adds Genie co-author attribution');
  console.log('');
  console.log(`  Hooks will be installed to: ${gitHooksDir}`);
  if (isWorktree) {
    console.log(`  ${YELLOW}Note: You're in a worktree - hooks install to main repo${RESET}`);
  }
  console.log('');

  // Define hooks to install
  const hooks = [
    { name: 'pre-commit', extension: '.cjs', runtime: 'node' },
    { name: 'pre-push', extension: '.cjs', runtime: 'node' },
    { name: 'prepare-commit-msg', extension: '', runtime: 'python3' }
  ];

  let installed = 0;
  let skipped = 0;
  let errors = [];

  for (const hook of hooks) {
    const source = path.join(hooksSourceDir, hook.name + hook.extension);
    const dest = path.join(gitHooksDir, hook.name);

    if (!fs.existsSync(source)) {
      console.log(`${YELLOW}âŠ˜${RESET} Skipping ${hook.name} (template not found)`);
      skipped++;
      continue;
    }

    try {
      // Check if hook already exists
      if (fs.existsSync(dest)) {
        // Read existing hook to see if it's our wrapper
        const existingContent = fs.readFileSync(dest, 'utf8');
        if (existingContent.includes(source)) {
          console.log(`${BLUE}â†»${RESET} ${hook.name} (already installed, updating)`);
        } else {
          console.log(`${YELLOW}âš ${RESET} ${hook.name} (existing hook found, overwriting)`);
        }
      }

      // Create relative symlink (portable across all systems)
      // Symlinks work in:
      // - Linux âœ…
      // - macOS âœ…
      // - Windows 10+ with Git for Windows (symlink support) âœ…
      // - GitHub Actions âœ…
      // - WSL âœ…
      // Relative path: .git/hooks â†’ ../../.genie/scripts/hooks/<name>.<ext>
      const relativePath = path.relative(gitHooksDir, source);

      // Remove existing hook (file or symlink)
      if (fs.existsSync(dest)) {
        fs.unlinkSync(dest);
      } else {
        try {
          // Try to remove if it's a broken symlink
          if (fs.lstatSync(dest).isSymbolicLink()) {
            fs.unlinkSync(dest);
          }
        } catch {
          // Ignore - file doesn't exist
        }
      }

      // Create relative symlink
      try {
        fs.symlinkSync(relativePath, dest);
        fs.chmodSync(dest, 0o755);
      } catch (err) {
        // Fallback for Windows without symlink support: use wrapper script
        if (err.code === 'EACCES' || err.code === 'EPERM') {
          console.warn(`${YELLOW}âš   Symlinks not supported, using wrapper script${RESET}`);
          const wrapper = `#!/bin/sh\nexec node "$(dirname "$0")/${relativePath}" "$@"\n`;
          fs.writeFileSync(dest, wrapper, { mode: 0o755 });
        } else {
          throw err;
        }
      }

      console.log(`${GREEN}âœ“${RESET} ${hook.name} installed`);
      installed++;
    } catch (err) {
      console.error(`${RED}âœ—${RESET} ${hook.name} failed: ${err.message}`);
      errors.push({ hook: hook.name, error: err.message });
    }
  }

  console.log('');
  console.log(`${GREEN}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${RESET}`);
  console.log(`${GREEN}Results:${RESET}`);
  console.log(`  ${GREEN}âœ“${RESET} Installed: ${installed}`);
  if (skipped > 0) {
    console.log(`  ${YELLOW}âŠ˜${RESET} Skipped: ${skipped}`);
  }
  if (errors.length > 0) {
    console.log(`  ${RED}âœ—${RESET} Errors: ${errors.length}`);
  }
  console.log('');

  if (errors.length > 0) {
    console.error(`${RED}Errors encountered:${RESET}`);
    errors.forEach(e => console.error(`  - ${e.hook}: ${e.error}`));
    console.log('');
    process.exit(1);
  }

  if (installed > 0) {
    console.log(`${GREEN}âœ“ Hooks installed successfully!${RESET}`);
    console.log('');
    console.log(`${BLUE}Next steps:${RESET}`);
    console.log('  - Hooks will now run automatically on commit/push');
    console.log('  - To bypass hooks temporarily: git commit --no-verify');
    console.log('  - To disable co-author: export GENIE_DISABLE_COAUTHOR=1');
    console.log('  - To skip tests on push: export GENIE_SKIP_TESTS=1');
    console.log('');
  } else {
    console.log(`${YELLOW}âš  No hooks were installed${RESET}`);
    process.exit(1);
  }
}

// Run the installer
installGitHooks();
```

</details>

### âœ… `.genie/scripts/prevent-worktree-access.sh` (3.0 KB)

<details>
<summary>View new file content</summary>

```markdown
#!/bin/bash
# Prevent direct Forge worktree filesystem access
# Installed as pre-commit hook
# Part of Discovery #120-A.1: Filesystem Restrictions Audit

set -e

echo "ğŸ” Checking for forbidden Forge worktree access..."

# Forbidden patterns
PATTERNS=(
  # Hardcoded worktree paths
  "/var/tmp/automagik-forge/worktrees/"

  # Filesystem operations on worktree-related paths
  "fs\.readFileSync.*worktree"
  "fs\.writeFileSync.*worktree"
  "fs\.existsSync.*worktree"
  "fs\.mkdirSync.*worktree"
  "fs\.rmdirSync.*worktree"
  "fs\.unlinkSync.*worktree"

  # Session file operations (executor-specific)
  "locateSessionFile\("
  "tryLocateSessionFileBySessionId\("
)

# Exception patterns (allowed uses)
EXCEPTIONS=(
  # forge-executor.ts display-only path (no filesystem access)
  "src/cli/lib/forge-executor\.ts.*getWorktreePath"
  # Interface definitions (not actual usage)
  "src/cli/executors/types\.ts"
)

VIOLATIONS=0
VIOLATION_FILES=()

# Get staged files in src/cli/
STAGED_FILES=$(git diff --cached --name-only --diff-filter=ACM | grep "^src/cli/" || true)

if [ -z "$STAGED_FILES" ]; then
  echo "âœ… No src/cli/ files staged for commit"
  exit 0
fi

# Check each pattern
for pattern in "${PATTERNS[@]}"; do
  for file in $STAGED_FILES; do
    # Get the staged content
    STAGED_CONTENT=$(git diff --cached "$file")

    # Check if pattern matches
    if echo "$STAGED_CONTENT" | grep -qE "$pattern"; then
      # Check if this is an exception
      IS_EXCEPTION=false
      for exception in "${EXCEPTIONS[@]}"; do
        if echo "$file" | grep -qE "$exception"; then
          IS_EXCEPTION=true
          break
        fi
      done

      if [ "$IS_EXCEPTION" = false ]; then
        if [ $VIOLATIONS -eq 0 ]; then
          echo ""
          echo "âŒ BLOCKED: Direct worktree access detected"
          echo ""
        fi

        echo "ğŸ“ File: $file"
        echo "   Pattern: $pattern"
        echo "   Context:"
        echo "$STAGED_CONTENT" | grep -E "$pattern" -A 2 -B 2 | sed 's/^/   /'
        echo ""

        VIOLATIONS=$((VIOLATIONS + 1))
        VIOLATION_FILES+=("$file")
      fi
    fi
  done
done

if [ $VIOLATIONS -gt 0 ]; then
  echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
  echo "ğŸš« Commit blocked: $VIOLATIONS violation(s) found"
  echo ""
  echo "ğŸ”§ Use Forge API instead:"
  echo "   âœ… forgeClient.getTaskAttempt(sessionId)"
  echo "   âœ… forgeClient.getTaskAttemptLogs(sessionId)"
  echo "   âœ… forgeClient.followUpTaskAttempt(sessionId, prompt)"
  echo ""
  echo "ğŸ“š See: .genie/discovery/filesystem-restrictions-audit.md"
  echo ""
  echo "âš ï¸  Emergency bypass: git commit --no-verify"
  echo "   (Document why in commit message!)"
  echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
  exit 1
fi

echo "âœ… No worktree access violations detected"
exit 0
```

</details>

### âœ… `.genie/scripts/run-tests.cjs` (749.0 B)

<details>
<summary>View new file content</summary>

```markdown
#!/usr/bin/env node

const { spawn } = require('child_process');
const path = require('path');

async function main() {
  const repoRoot = path.join(__dirname, '..', '..');
  console.log('âš™ï¸  Running tests...');
  await new Promise((resolve) => {
    const ps = spawn('pnpm', ['run', 'test:all'], { stdio: 'inherit', cwd: repoRoot, shell: false });
    ps.on('exit', (code) => {
      if (code === 0) {
        console.log('âœ… Tests passed');
      } else {
        console.error(`âŒ Tests failed (exit code: ${code})`);
        console.error('   Fix failing tests before pushing');
      }
      process.exit(code || 0);
    });
  });
}

main().catch((e) => {
  console.error(`âŒ Error running tests: ${e.message}`);
  process.exit(1);
});
```

</details>

### âœ… `.genie/scripts/sync-qa-from-issues.cjs` (4.5 KB)

<details>
<summary>View new file content</summary>

```markdown
#!/usr/bin/env node

const { execSync } = require('child_process');
const fs = require('fs');
const path = require('path');

function fetchIssues() {
  try {
    const out = execSync('gh issue list --label type:bug --state all --json number,title,labels,state,createdAt,body --limit 1000', { encoding: 'utf8' });
    return JSON.parse(out);
  } catch (e) {
    console.error(`Error fetching issues: ${e.stderr || e.message}`);
    process.exit(1);
  }
}

function extractSections(body) {
  if (!body) return { description: 'No description provided' };
  const sections = {}; let current = 'description'; let buf = [];
  for (const line of body.split('\n')) {
    if (line.trim().startsWith('##')) { if (buf.length) sections[current] = buf.join('\n').trim(); current = line.replace(/^#+/,'').trim().toLowerCase().replace(/\s+/g,'_'); buf = []; }
    else if (line.trim().startsWith('**') && line.trim().endsWith('**')) { if (buf.length) sections[current] = buf.join('\n').trim(); current = line.replace(/\*/g,'').trim().toLowerCase().replace(/\s+/g,'_'); buf = []; }
    else buf.push(line);
  }
  if (buf.length) sections[current] = buf.join('\n').trim();
  return sections;
}

function formatScenario(issue) {
  const number = issue.number;
  const title = issue.title;
  const state = issue.state;
  const created = issue.createdAt.slice(0,10);
  const labels = (issue.labels || []).map((l) => l.name);
  const sections = extractSections(issue.body || '');
  const status = state === 'CLOSED' ? 'âœ… Fixed' : 'ğŸ”´ Open';
  let s = `## Bug #${number}: ${title}\n**Status:** ${status}\n**Labels:** ${labels.join(', ')}\n**Created:** ${created}\n**GitHub:** https://github.com/namastexlabs/automagik-genie/issues/${number}\n\n`;
  const repro = sections.reproduction_steps || sections.steps_to_reproduce;
  if (repro) s += `### Reproduction Steps\n${repro}\n\n`;
  const expected = sections.expected_behavior || sections.expected;
  if (expected) s += `### Expected Behavior\n${expected}\n\n`;
  const actual = sections.actual_behavior || sections.actual;
  if (actual) s += `### Actual Behavior\n${actual}\n\n`;
  if (sections.description && !(repro || expected)) s += `### Description\n${sections.description}\n\n`;
  s += `### Validation\n- [${state === 'OPEN' ? ' ' : 'x'}] Bug verified fixed\n- [ ] Test scenario executed\n- [ ] Regression test added\n- [ ] Documentation updated\n\n---\n\n`;
  return s;
}

function main() {
  const dryRun = process.argv.includes('--dry-run');
  console.log('ğŸ“‹ Fetching GitHub issues...');
  const issues = fetchIssues();
  console.log(`   Found ${issues.length} bug issues`);
  const ts = new Date().toISOString().replace('T',' ').replace(/\..+/, ' UTC');
  const openBugs = issues.filter((i) => i.state === 'OPEN');
  const fixedBugs = issues.filter((i) => i.state === 'CLOSED');
  let content = `# QA Scenarios from GitHub Issues\n**Auto-Generated:** ${ts}\n**Source:** GitHub Issues with label \`type:bug\`\n**Script:** \`.genie/scripts/sync-qa-from-issues.js\`\n\n---\n\n## Summary\n\n**Total Bugs:** ${issues.length}\n- ğŸ”´ Open: ${openBugs.length}\n- âœ… Fixed: ${fixedBugs.length}\n\n---\n\n## Open Bugs\n\n`;
  if (openBugs.length) openBugs.sort((a,b)=>a.number-b.number).forEach((i) => { content += formatScenario(i); }); else content += '*No open bugs found.*\n\n';
  content += `---\n\n## Fixed Bugs\n\n`;
  if (fixedBugs.length) fixedBugs.sort((a,b)=>b.number-a.number).forEach((i) => { content += formatScenario(i); }); else content += '*No fixed bugs found.*\n\n';
  content += `---\n\n## Usage\n\nThis file is auto-generated from GitHub issues. To update:\n\n\`\`\`bash\nnode .genie/scripts/sync-qa-from-issues.js\n\`\`\`\n\nTo run manually with dry-run:\n\n\`\`\`bash\nnode .genie/scripts/sync-qa-from-issues.js --dry-run\n\`\`\`\n\nTo automate via GitHub Actions (future):\n- Add workflow trigger: daily or on issue close\n- Run script and commit changes\n- Track regression coverage\n`;
  if (dryRun) {
    console.log('\n--- DRY RUN OUTPUT ---');
    console.log(content);
    console.log('\n--- END DRY RUN ---');
    console.log('\nâ„¹ï¸  Dry run complete. No files written.');
    return;
  }
  const outPath = path.join(__dirname, '..', 'qa', 'scenarios-from-bugs.md');
  fs.mkdirSync(path.dirname(outPath), { recursive: true });
  fs.writeFileSync(outPath, content);
  console.log(`âœ… Scenarios written to: ${outPath}`);
  console.log('\nğŸ“Š Summary:');
  console.log(`   - Total bugs: ${issues.length}`);
  console.log(`   - Open: ${openBugs.length}`);
  console.log(`   - Fixed: ${fixedBugs.length}`);
}

main();
```

</details>

### âœ… `.genie/scripts/token-efficiency/count-tokens.cjs` (7.2 KB)

<details>
<summary>View new file content</summary>

```markdown
#!/usr/bin/env node
/**
 * Count tokens for all Markdown files and produce reports under .genie/state/.
 */
const fs = require('fs');
const path = require('path');

const ROOT = process.cwd();
const STATE = path.join(ROOT, '.genie', 'state');
const JSON_OUT = path.join(STATE, 'token-usage.json');
const MD_OUT = path.join(STATE, 'token-usage.md');

function ensureDir(p) { fs.mkdirSync(p, { recursive: true }); }
function readDir(p) { try { return fs.readdirSync(p, { withFileTypes: true }); } catch { return []; } }
function isDir(p) { try { return fs.statSync(p).isDirectory(); } catch { return false; } }

function shouldSkip(rel) {
  return (
    rel.startsWith('.git/') ||
    rel.startsWith('node_modules/') ||
    rel.startsWith('forge/') ||  // Skip entire forge directory
    rel.startsWith('.genie/backups/') ||  // Skip backup directories (can contain 500K+ files)
    rel.includes('/dist/') ||
    rel.includes('/node_modules/') ||
    rel.includes('/.pnpm-store/') ||
    rel.includes('/.pnpm/')
  );
}

function listMarkdownFiles(root) {
  const files = [];
  function walk(dir) {
    for (const entry of readDir(dir)) {
      const full = path.join(dir, entry.name);
      const rel = path.relative(root, full).replace(/\\/g, '/');
      if (entry.isDirectory()) {
        if (!shouldSkip(rel + '/')) walk(full);
      } else if (entry.isFile() && entry.name.toLowerCase().endsWith('.md')) {
        if (!shouldSkip(rel)) files.push(rel);
      }
    }
  }
  walk(root);
  return files.sort((a,b)=>a.localeCompare(b));
}

function countTokens(text) {
  try {
    const { get_encoding } = require('js-tiktoken');
    const encName = process.env.TOKEN_ENCODING || 'cl100k_base';
    const encoder = get_encoding(encName);
    const count = encoder.encode(text).length;
    try { encoder.free && encoder.free(); } catch {}
    return { tokens: count, method: 'tiktoken', encoding: encName };
  } catch {
    const approx = (text || '').trim().split(/\s+/).filter(Boolean).length;
    return { tokens: approx, method: 'approx', encoding: 'approx-words' };
  }
}

function writeSummary(results, meta) {
  ensureDir(STATE);
  fs.writeFileSync(JSON_OUT, JSON.stringify(meta, null, 2), 'utf8');

  const top = parseInt(process.env.TOKEN_TOP || '30', 10);
  const lines = [];
  lines.push('# Token Usage');
  lines.push(`Generated: ${meta.generatedAt} | Encoding: ${meta.encoding}`);
  lines.push(`Total Files: ${meta.totals.files} | Total Tokens: ${meta.totals.tokens}`);
  lines.push('');
  lines.push(`## Top ${Math.min(top, results.length)} Files by Tokens`);
  results.slice(0, top).forEach(r => {
    lines.push(`- ${r.tokens.toString().padStart(6, ' ')} | ${r.path}`);
  });
  lines.push('');
  lines.push('> Tip: Keep large docs lean; use @ references instead of duplicating content.');
  fs.writeFileSync(MD_OUT, lines.join('\n'), 'utf8');

  try { require('child_process').execSync(`git add ${JSON_OUT} ${MD_OUT}`, { stdio: 'ignore' }); } catch {}
  console.log(`- Notes: Token usage updated (${results.length} files)`);
}

function getFileHash(content) {
  // Simple hash: file size + first/last 100 chars
  const len = content.length;
  const sample = content.slice(0, 100) + len + content.slice(-100);
  return Buffer.from(sample).toString('base64').slice(0, 32);
}

function loadCache() {
  try {
    const cachePath = path.join(STATE, 'token-cache.json');
    const cache = JSON.parse(fs.readFileSync(cachePath, 'utf8'));

    // Prune stale entries (files that no longer exist or match skip patterns)
    const validCache = {};
    let prunedCount = 0;

    for (const [relPath, entry] of Object.entries(cache)) {
      // Preserve metadata
      if (relPath === '__meta') {
        validCache.__meta = entry;
        continue;
      }

      // Skip entries that should be excluded
      if (shouldSkip(relPath)) {
        prunedCount++;
        continue;
      }

      // Skip entries for files that no longer exist
      const fullPath = path.join(ROOT, relPath);
      if (!fs.existsSync(fullPath)) {
        prunedCount++;
        continue;
      }

      validCache[relPath] = entry;
    }

    if (prunedCount > 0) {
      console.log(`  ğŸ§¹ Pruned ${prunedCount} stale cache entries`);
    }

    return validCache;
  } catch {
    return {};
  }
}

function saveCache(cache) {
  try {
    const cachePath = path.join(STATE, 'token-cache.json');
    ensureDir(STATE);
    // Add metadata timestamp for incremental detection
    cache.__meta = { timestamp: Date.now() };
    fs.writeFileSync(cachePath, JSON.stringify(cache, null, 2), 'utf8');
  } catch {}
}

function main() {
  const cache = loadCache();
  const cacheAge = cache.__meta?.timestamp || 0;
  const cacheAgeMinutes = (Date.now() - cacheAge) / 60000;

  // If cache is fresh (<5 min old), trust it entirely without scanning
  if (cacheAge > 0 && cacheAgeMinutes < 5) {
    console.log(`  âš¡ Cache is fresh (${cacheAgeMinutes.toFixed(1)}m old), skipping scan`);

    // Rebuild results from cache
    const results = [];
    let totalTokens = 0;
    let encodingUsed = null;

    for (const [relPath, entry] of Object.entries(cache)) {
      if (relPath === '__meta') continue;
      totalTokens += entry.tokens;
      if (!encodingUsed) encodingUsed = entry.encoding;
      results.push({ path: relPath, tokens: entry.tokens, lines: entry.lines, bytes: entry.bytes, method: entry.method });
    }

    results.sort((a,b)=> b.tokens - a.tokens);
    const meta = {
      generatedAt: new Date().toISOString(),
      encoding: encodingUsed,
      files: results,
      totals: { files: results.length, tokens: totalTokens }
    };

    writeSummary(results, meta);
    return;
  }

  // Cache is stale or missing, do full scan
  console.log(`  ğŸ”„ Cache stale (${cacheAgeMinutes.toFixed(1)}m old), scanning...`);
  const files = listMarkdownFiles(ROOT);

  const results = [];
  let totalTokens = 0;
  let encodingUsed = null;
  let cacheHits = 0;

  for (const rel of files) {
    const full = path.join(ROOT, rel);
    let content = '';
    try { content = fs.readFileSync(full, 'utf8'); } catch { continue; }

    const hash = getFileHash(content);
    const cached = cache[rel];

    // Use cached result if hash matches
    if (cached && cached.hash === hash) {
      cacheHits++;
      totalTokens += cached.tokens;
      if (!encodingUsed) encodingUsed = cached.encoding;
      results.push({ path: rel, tokens: cached.tokens, lines: cached.lines, bytes: cached.bytes, method: cached.method });
      continue;
    }

    // Recount this file
    const { tokens, method, encoding } = countTokens(content);
    if (!encodingUsed) encodingUsed = encoding;
    totalTokens += tokens;
    const lines = (content.match(/\n/g) || []).length + 1;
    const bytes = Buffer.byteLength(content, 'utf8');

    results.push({ path: rel, tokens, lines, bytes, method });
    cache[rel] = { hash, tokens, lines, bytes, method, encoding };
  }

  results.sort((a,b)=> b.tokens - a.tokens);
  const meta = {
    generatedAt: new Date().toISOString(),
    encoding: encodingUsed,
    files: results,
    totals: { files: results.length, tokens: totalTokens }
  };

  saveCache(cache);
  writeSummary(results, meta);

  if (cacheHits > 0) {
    console.log(`  âš¡ Cache: ${cacheHits}/${files.length} files unchanged`);
  }
}

try { main(); } catch (e) {
  console.error('âŒ Token usage failed:', e?.message || e);
  process.exit(0);
}
```

</details>

### âœ… `.genie/scripts/token-efficiency/quality-gate.cjs` (3.3 KB)

<details>
<summary>View new file content</summary>

```markdown
#!/usr/bin/env node
/**
 * Token Quality Gate
 * Compares current token usage (token-usage.json) with baseline and prints a minimal summary.
 */
const fs = require('fs');
const path = require('path');

const ROOT = process.cwd();
const STATE = path.join(ROOT, '.genie', 'state');
const CURRENT_PATH = path.join(STATE, 'token-usage.json');
const BASELINE_PATH = path.join(STATE, 'token-usage-baseline.json');
const TOP_MD = path.join(STATE, 'token-usage.md');

function readJson(p) { try { return JSON.parse(fs.readFileSync(p, 'utf8')); } catch { return null; } }
function writeJson(p, obj) { fs.mkdirSync(path.dirname(p), { recursive: true }); fs.writeFileSync(p, JSON.stringify(obj, null, 2), 'utf8'); }

function print(lines) { lines.forEach(l => console.log(l)); }

function summarize(current, baseline) {
  if (!current || !current.totals) {
    return ['- Result: âš ï¸ Token usage data missing', '- Reinforcer: Ensure count-tokens script runs before commit'];
  }
  const currentTokens = current.totals.tokens;
  if (!baseline || !baseline.totals) {
    writeJson(BASELINE_PATH, current);
    return [
      `- Result: ğŸ§­ Baseline initialized (tokens=${currentTokens})`,
      '- Reinforcer: Keep outputs concise; prefer @ references over duplication'
    ];
  }
  const prevTokens = baseline.totals.tokens;
  const delta = currentTokens - prevTokens;
  const pct = prevTokens ? ((delta / prevTokens) * 100).toFixed(1) : '0.0';
  const statusEmoji = delta > 0 ? 'âš ï¸' : 'âœ…';
  writeJson(BASELINE_PATH, current);
  return [
    `- Result: ${statusEmoji} Token usage ${delta >= 0 ? '+' : ''}${delta} (${delta >= 0 ? '+' : ''}${pct}%)`,
    '- Reinforcer: Split large docs; link via @ to re-use content'
  ];
}

function topGrowth(current, baseline, limit = 3) {
  if (!current || !current.files) return [];
  const prior = new Map();
  if (baseline && baseline.files) baseline.files.forEach(f => prior.set(f.path, f.tokens));
  return current.files
    .map(f => ({ path: f.path, delta: f.tokens - (prior.get(f.path) || 0) }))
    .filter(f => f.delta > 0)
    .sort((a,b)=> b.delta - a.delta)
    .slice(0, limit);
}

function sampleTop(mdPath, limit = 3) {
  try {
    const lines = fs.readFileSync(mdPath, 'utf8').split(/\r?\n/);
    const start = lines.findIndex(l => l.startsWith('## Top'));
    if (start !== -1) {
      const picks = [];
      for (let i = start + 1; i < lines.length && picks.length < limit; i++) {
        const line = lines[i];
        if (line.startsWith('- ')) picks.push(line);
        else if (!line.trim()) break;
      }
      return picks;
    }
  } catch {}
  return [];
}

function main() {
  const current = readJson(CURRENT_PATH);
  const baseline = readJson(BASELINE_PATH);

  console.log('- Notes: Token quality');
  print(summarize(current, baseline));

  const growth = topGrowth(current, baseline);
  if (growth.length) {
    console.log('- Notes: Top growth files');
    growth.forEach(g => console.log(`  - +${g.delta} | ${g.path}`));
  }

  const heavy = sampleTop(TOP_MD);
  if (heavy.length) {
    console.log('- Notes: Current heavy files');
    heavy.forEach(line => console.log(`  ${line}`));
  }

  try { require('child_process').execSync(`git add ${BASELINE_PATH}`, { stdio: 'ignore' }); } catch {}
}

try { main(); } catch (e) {
  console.error('âŒ Token quality gate failed:', e?.message || e);
}
```

</details>

### âœ… `.genie/scripts/update-changelog.cjs` (7.7 KB)

<details>
<summary>View new file content</summary>

```markdown
#!/usr/bin/env node

/**
 * CHANGELOG Manager (Node port)
 *
 * Modes:
 * - rc <version>: move [Unreleased] entries into a new version section
 * - stable <version>: promote RC section to stable version
 * - default: ensure [Unreleased] section exists (generate from commits if missing)
 */

const fs = require('fs');
const path = require('path');
const { execSync, spawnSync } = require('child_process');

const ACTION = process.argv[2]; // rc|stable|undefined
const VERSION = process.argv[3];
const REPO_ROOT = path.join(__dirname, '..', '..');
const CHANGELOG_PATH = path.join(REPO_ROOT, 'CHANGELOG.md');

function log(color, emoji, message) {
  const colors = {
    reset: '\x1b[0m', red: '\x1b[31m', green: '\x1b[32m', yellow: '\x1b[33m', blue: '\x1b[34m'
  };
  console.log(`${colors[color] || ''}${emoji} ${message}${colors.reset}`);
}

function todayISO() {
  const d = new Date();
  return new Date(Date.UTC(d.getUTCFullYear(), d.getUTCMonth(), d.getUTCDate()))
    .toISOString().slice(0, 10);
}

function readLines(filePath) {
  const text = fs.readFileSync(filePath, 'utf8');
  return text.split(/\r?\n/);
}

function writeLines(filePath, lines) {
  let content = lines.join('\n');
  if (!content.endsWith('\n')) content += '\n';
  fs.writeFileSync(filePath, content, 'utf8');
}

function indexOfNextVersionHeader(lines, startIdx) {
  for (let i = startIdx; i < lines.length; i++) {
    if (lines[i].startsWith('## [')) return i;
  }
  return -1;
}

function ensureChangelogFile() {
  if (!fs.existsSync(CHANGELOG_PATH)) {
    throw new Error(`CHANGELOG not found at ${CHANGELOG_PATH}`);
  }
}

function stageChangelog() {
  try {
    execSync(`git add ${JSON.stringify(CHANGELOG_PATH)}`);
  } catch {}
}

// Default mode: generate [Unreleased] section if missing
function getLastTag() {
  try {
    return execSync('git describe --tags --abbrev=0', { encoding: 'utf8' }).trim();
  } catch {
    return null;
  }
}

function getCommitsSince(tag) {
  try {
    const range = tag ? `${tag}..HEAD` : 'HEAD';
    const out = execSync(`git log ${range} --oneline --no-merges`, { encoding: 'utf8' }).trim();
    return out ? out.split('\n') : [];
  } catch {
    return [];
  }
}

function parseCommitLine(line) {
  // abcd123 feat: message
  const m = line.match(/^([a-f0-9]+)\s+(.+)$/);
  if (!m) return null;
  const hash = m[1];
  const msg = m[2];
  const t = msg.match(/^(feat|fix|refactor|docs|chore|test|perf):\s+(.+)$/);
  if (t) return { hash, type: t[1], message: t[2] };
  return { hash, type: 'other', message: msg };
}

function generateUnreleasedSection(commits) {
  const groups = { feat: [], fix: [], refactor: [], docs: [], test: [], perf: [], chore: [], other: [] };
  commits.forEach((line) => {
    const p = parseCommitLine(line);
    if (!p) return;
    groups[p.type] = groups[p.type] || [];
    groups[p.type].push(p);
  });

  const typeHeaders = {
    feat: '### Features',
    fix: '### Fixes',
    refactor: '### Refactor',
    docs: '### Documentation',
    test: '### Tests',
    perf: '### Performance',
    chore: '### Chore',
    other: '### Other',
  };

  const lines = ['## [Unreleased]', ''];
  for (const key of ['feat', 'fix', 'refactor', 'docs', 'test', 'perf', 'chore', 'other']) {
    const items = groups[key];
    if (!items || items.length === 0) continue;
    lines.push(typeHeaders[key]);
    items.forEach((c) => lines.push(`- ${c.message} (${c.hash})`));
    lines.push('');
  }
  return lines.join('\n');
}

function ensureUnreleased() {
  ensureChangelogFile();
  const existing = fs.readFileSync(CHANGELOG_PATH, 'utf8');
  if (existing.includes('[Unreleased]')) {
    // Already exists - this is the desired state, no warning needed
    return 0;
  }
  const last = getLastTag();
  if (last) console.log(`   Last tag: ${last}`);
  const commits = getCommitsSince(last);
  if (commits.length === 0) {
    console.log('   No new commits since last tag');
    console.log('âœ… CHANGELOG up to date');
    return 0;
  }
  console.log(`   Found ${commits.length} commits`);
  const newSection = generateUnreleasedSection(commits);

  // Insert after header (first blank line after first line)
  let headerEnd = existing.indexOf('\n\n');
  if (headerEnd === -1) headerEnd = existing.length;
  const updated = existing.slice(0, headerEnd + 2) + newSection + '\n' + existing.slice(headerEnd + 2);
  fs.writeFileSync(CHANGELOG_PATH, updated, 'utf8');
  stageChangelog();
  console.log('âœ… CHANGELOG updated and staged');
  return 0;
}

function prepareRC(version) {
  ensureChangelogFile();
  const lines = readLines(CHANGELOG_PATH);
  const unreleasedIdx = lines.findIndex((l) => l.trim() === '## [Unreleased]');
  if (unreleasedIdx === -1) {
    console.error('âŒ Missing "## [Unreleased]" section. Aborting.');
    return 1;
  }
  const contentStart = unreleasedIdx + 1;
  const macroIdx = lines.findIndex((l, i) => i >= contentStart && (l.startsWith('**Current Version:**') || l.startsWith('**Generated:**')));
  let contentEnd = indexOfNextVersionHeader(lines, contentStart);
  if (macroIdx !== -1) contentEnd = macroIdx;
  if (contentEnd === -1) contentEnd = lines.length;

  const extracted = lines.slice(contentStart, contentEnd).filter((l) => {
    if (!l.trim()) return false;
    if (l.startsWith('All notable changes')) return false;
    if (l.trim() === '---') return false;
    return true;
  });
  const movedCount = extracted.length;

  const keepHead = lines.slice(0, contentStart);
  const keepTail = lines.slice(contentEnd);
  const beforeInsert = keepHead.concat(keepTail);
  const insertAt = beforeInsert.findIndex((l, i) => i > unreleasedIdx && l.startsWith('## ['));
  if (insertAt === -1) {
    console.error('âŒ Could not find first version section to anchor insertion.');
    return 1;
  }

  const header = `## [${version}] - ${todayISO()}`;
  const section = [header, ''];
  if (movedCount > 0) section.push(...extracted); else section.push('No changelog entries (packaging-only RC).');
  section.push('');

  const updated = beforeInsert.slice(0, insertAt).concat(section).concat(beforeInsert.slice(insertAt));
  writeLines(CHANGELOG_PATH, updated);
  stageChangelog();
  log('green', 'âœ…', `CHANGELOG updated for RC ${version} (moved ${movedCount} lines)`);
  return 0;
}

function promoteStable(version) {
  ensureChangelogFile();
  const lines = readLines(CHANGELOG_PATH);
  const base = version;
  let rcIdx = -1;
  for (let i = 0; i < lines.length; i++) {
    if (lines[i].startsWith('## [') && lines[i].includes(`${base}-rc.`)) { rcIdx = i; break; }
  }
  if (rcIdx !== -1) {
    lines[rcIdx] = `## [${base}] - ${todayISO()}`;
    writeLines(CHANGELOG_PATH, lines);
    stageChangelog();
    log('green', 'âœ…', `Promoted RC section to stable ${base}`);
    return 0;
  }
  // Insert minimal section near top (after '---' if present, else before first version)
  const sepIdx = lines.findIndex((l) => l.trim() === '---');
  const firstVerIdx = indexOfNextVersionHeader(lines, 0);
  const anchor = sepIdx !== -1 ? sepIdx + 1 : (firstVerIdx !== -1 ? firstVerIdx : lines.length);
  const header = `## [${base}] - ${todayISO()}`;
  const section = [header, '', 'No changes since last RC.', ''];
  const updated = lines.slice(0, anchor).concat(section).concat(lines.slice(anchor));
  writeLines(CHANGELOG_PATH, updated);
  stageChangelog();
  log('green', 'âœ…', `Inserted stable section ${base}`);
  return 0;
}

function main() {
  if (ACTION === 'rc') {
    if (!VERSION) {
      console.error('Usage: update-changelog.js rc <version>');
      process.exit(1);
    }
    process.exit(prepareRC(VERSION));
  }

  if (ACTION === 'stable') {
    if (!VERSION) {
      console.error('Usage: update-changelog.js stable <version>');
      process.exit(1);
    }
    process.exit(promoteStable(VERSION));
  }

  // default: ensure [Unreleased]
  process.exit(ensureUnreleased());
}

main();
```

</details>

### âœ… `.genie/scripts/validate-cross-references.cjs` (4.2 KB)

<details>
<summary>View new file content</summary>

```markdown
#!/usr/bin/env node

const fs = require('fs');
const path = require('path');

function walk(dir, files = []) {
  const entries = fs.readdirSync(dir, { withFileTypes: true });
  for (const e of entries) {
    const p = path.join(dir, e.name);
    if (e.isDirectory()) {
      const name = e.name;
      if (['.git', 'node_modules', 'dist', 'build', 'research'].includes(name)) continue;
      if (p.includes(path.join('.genie', 'state'))) continue;
      if (p.includes(path.join('.genie', 'backups'))) continue;
      walk(p, files);
    } else {
      const lower = e.name.toLowerCase();
      if (lower.endsWith('.md')) files.push(p);
    }
  }
  return files;
}

function isInCodeBlock(content, matchStart) {
  const before = content.slice(0, matchStart);
  const fenceTicks = (before.match(/```/g) || []).length;
  const fenceTildes = (before.match(/~~~/g) || []).length;
  if (fenceTicks % 2 === 1 || fenceTildes % 2 === 1) return true;
  // Inline code within the same line
  const lastNewline = before.lastIndexOf('\n');
  const lineStart = lastNewline === -1 ? 0 : lastNewline;
  const line = content.slice(lineStart, content.indexOf('\n', matchStart) === -1 ? content.length : content.indexOf('\n', matchStart));
  const backticksBefore = (line.slice(0, matchStart - lineStart).match(/`/g) || []).length;
  return backticksBefore % 2 === 1;
}

function isFalsePositive(refPath, context) {
  if (/^[\w\-]+\.(com|ai|org|net|io|dev|co|edu|gov)$/.test(refPath)) return true; // email domains
  if (['next', 'latest', 'canary', 'rc', 'beta', 'alpha'].includes(refPath)) return true; // tags
  if (/^\d+\.\d+\.\d+(-[\w.]+)?$/.test(refPath)) return true; // versions
  if (refPath.includes('/') && !refPath.endsWith('.md') && !refPath.endsWith('/')) {
    const parts = refPath.split('/');
    if (parts.length === 2) return true; // @org/package
  }
  const placeholders = ['file.md', 'directory/', 'path', 'include', 'mcp', '...', 'X.Y.Z', 'roadmap', 'standards'];
  if (placeholders.includes(refPath)) return true;
  if (refPath.startsWith('agent-')) return true;
  if (/^[\w\-]{1,29}$/.test(refPath)) {
    const patterns = ['RASCI', 'Responsible:', 'Accountable:', 'Support:', 'Consulted:', 'Informed:', '@username', '@teams', '@eng-team', '@stakeholders', 'twitter.com', 'github.com', 'Follow', 'Discord'];
    if (patterns.some((p) => context.includes(p))) return true;
  }
  if (refPath.includes(':')) return true; // resource identifiers
  return false;
}

function extractRefs(filePath) {
  let content;
  try { content = fs.readFileSync(filePath, 'utf8'); } catch (e) { return []; }
  const refs = [];
  const re = /@([\w\-.\/]+(?:\.md|\/)?)(?:\s|$|[^\w\-.\/:] )/g;
  let m;
  while ((m = re.exec(content))) {
    if (isInCodeBlock(content, m.index)) continue;
    const refPath = m[1];
    const line = content.slice(0, m.index).split(/\n/).length;
    const start = Math.max(0, m.index - 50);
    const end = Math.min(content.length, m.index + 50);
    const context = content.slice(start, end);
    if (isFalsePositive(refPath, context)) continue;
    refs.push({ refPath, line });
  }
  return refs;
}

function main() {
  const repoRoot = path.join(__dirname, '..', '..');
  console.log('ğŸ” Validating @ cross-references...');
  const files = walk(repoRoot);
  console.log(`   Found ${files.length} markdown files to check`);
  const broken = [];
  for (const f of files) {
    const refs = extractRefs(f);
    for (const r of refs) {
      const target = path.join(repoRoot, r.refPath);
      const ok = r.refPath.endsWith('/') ? fs.existsSync(target) && fs.statSync(target).isDirectory() : fs.existsSync(target) && fs.statSync(target).isFile();
      if (!ok) {
        broken.push({ source: path.relative(repoRoot, f), line: r.line, reference: r.refPath, error: r.refPath.endsWith('/') ? 'Directory not found' : 'File not found' });
      }
    }
  }
  if (broken.length) {
    console.error(`\nâŒ Found ${broken.length} broken @ reference(s):\n`);
    for (const b of broken) {
      console.error(`   ${b.source}:${b.line}`);
      console.error(`      @${b.reference}`);
      console.error(`      ${b.error}`);
      console.error('');
    }
    console.error('Fix broken references before committing.');
    process.exit(1);
  }
  console.log('âœ… All @ cross-references valid');
}

main();
```

</details>

### âœ… `.genie/scripts/validate-mcp-build.cjs` (4.2 KB)

<details>
<summary>View new file content</summary>

```markdown
#!/usr/bin/env node
/**
 * Validate MCP Build - Ensure dist files are in sync with source
 *
 * Purpose:
 * - Prevent accidental deletion of MCP dist files
 * - Ensure HTML files are copied from src to dist
 * - Validate TypeScript compilation is up-to-date
 *
 * Triggered by: pre-commit hook
 * Exit codes: 0 = valid, 1 = needs rebuild
 */

const { execSync } = require('child_process');
const fs = require('fs');
const path = require('path');

const gitRoot = execSync('git rev-parse --show-toplevel', { encoding: 'utf8' }).trim();

/**
 * Get list of staged files from git
 */
function getStagedFiles() {
  try {
    const output = execSync('git diff --cached --name-only', { encoding: 'utf8' }).trim();
    if (!output) return [];
    return output.split('\n').filter(Boolean);
  } catch (error) {
    return [];
  }
}

/**
 * Check if any MCP-related files are staged
 */
function hasMCPChanges(stagedFiles) {
  return stagedFiles.some(file =>
    file.startsWith('src/mcp/') ||
    file.startsWith('dist/mcp/')
  );
}

/**
 * Check if HTML files exist in dist
 */
function validateHTMLFiles() {
  const errors = [];

  // Check if authorize.html exists in dist
  const srcHtml = path.join(gitRoot, 'src/mcp/lib/views/authorize.html');
  const distHtml = path.join(gitRoot, 'dist/mcp/lib/views/authorize.html');

  if (fs.existsSync(srcHtml) && !fs.existsSync(distHtml)) {
    errors.push({
      file: 'authorize.html',
      message: 'HTML file exists in src/ but missing from dist/'
    });
  }

  // Check if files are identical (if both exist)
  if (fs.existsSync(srcHtml) && fs.existsSync(distHtml)) {
    const srcContent = fs.readFileSync(srcHtml, 'utf8');
    const distContent = fs.readFileSync(distHtml, 'utf8');

    if (srcContent !== distContent) {
      errors.push({
        file: 'authorize.html',
        message: 'HTML file in dist/ is out of sync with src/'
      });
    }
  }

  return errors;
}

/**
 * Check if TypeScript files are compiled
 */
function validateTypeScriptBuild(stagedFiles) {
  const errors = [];

  // Get all staged .ts files in src/
  const stagedTsFiles = stagedFiles.filter(file =>
    file.startsWith('src/mcp/') && file.endsWith('.ts')
  );

  for (const tsFile of stagedTsFiles) {
    const srcPath = path.join(gitRoot, tsFile);

    // Skip deleted files (they won't exist in filesystem)
    if (!fs.existsSync(srcPath)) {
      continue; // File deleted - no validation needed
    }

    // Convert src path to expected dist path
    const distFile = tsFile
      .replace('src/mcp/', 'dist/mcp/')
      .replace(/\.ts$/, '.js');

    const distPath = path.join(gitRoot, distFile);

    // Check if compiled file exists
    if (!fs.existsSync(distPath)) {
      errors.push({
        file: tsFile,
        message: `TypeScript file staged but compiled output missing: ${distFile}`
      });
    } else {
      // Check if source is newer than compiled output
      const srcMtime = fs.statSync(srcPath).mtime;
      const distMtime = fs.statSync(distPath).mtime;

      if (srcMtime > distMtime) {
        errors.push({
          file: tsFile,
          message: `Source file is newer than compiled output (${distFile})`
        });
      }
    }
  }

  return errors;
}

/**
 * Main validation logic
 */
function main() {
  const stagedFiles = getStagedFiles();

  // Skip validation if no MCP files are staged
  if (!hasMCPChanges(stagedFiles)) {
    return 0; // Success - no validation needed
  }

  let hasErrors = false;
  const allErrors = [];

  // Validate HTML files
  const htmlErrors = validateHTMLFiles();
  if (htmlErrors.length > 0) {
    hasErrors = true;
    allErrors.push(...htmlErrors);
  }

  // Validate TypeScript compilation
  const tsErrors = validateTypeScriptBuild(stagedFiles);
  if (tsErrors.length > 0) {
    hasErrors = true;
    allErrors.push(...tsErrors);
  }

  if (hasErrors) {
    console.error('âŒ MCP build validation failed:\n');

    for (const error of allErrors) {
      console.error(`   ${error.file}`);
      console.error(`   â””â”€ ${error.message}\n`);
    }

    console.error('ğŸ”§ Fix by running:');
    console.error('   pnpm run build:mcp');
    console.error('   git add dist/mcp/\n');

    return 1; // Failure
  }

  console.log('âœ… MCP build validation passed');
  return 0; // Success
}

process.exit(main());
```

</details>

### âœ… `.genie/scripts/validate-user-files-not-committed.cjs` (1.2 KB)

<details>
<summary>View new file content</summary>

```markdown
#!/usr/bin/env node

const { execSync } = require('child_process');

function getStagedFiles() {
  try {
    const out = execSync('git diff --cached --name-only', { encoding: 'utf8' }).trim();
    return out ? out.split('\n') : [];
  } catch (e) {
    console.error(`âŒ Error getting staged files: ${e.message}`);
    return [];
  }
}

function main() {
  const staged = getStagedFiles();
  if (!staged.length) process.exit(0);
  const violations = ['.genie/TODO.md', '.genie/USERCONTEXT.md'].filter((f) => staged.includes(f));
  if (violations.length) {
    console.error('âŒ User files detected in commit (should be gitignored):\n');
    violations.forEach((v) => console.error(`   ${v}`));
    console.error('\nThese files are personal and should never be committed.\n');
    console.error('Fix:');
    console.error('  1. Unstage files:');
    violations.forEach((v) => console.error(`       git reset HEAD ${v}`));
    console.error('  2. Verify .gitignore contains:');
    console.error('       .genie/TODO.md');
    console.error('       .genie/USERCONTEXT.md');
    console.error('  3. Retry commit\n');
    process.exit(1);
  }
  console.log('âœ… User files validation passed (no personal files in commit)');
}

main();
```

</details>

### âœ… `.genie/utilities/AGENTS.md` (182.0 B)

<details>
<summary>View new file content</summary>

```markdown
# Utilities Collective

Utility agents for infrastructure and automation tasks.

## Agents

- **upstream-update**: Automate upstream dependency updates with comprehensive validation
```

</details>

### âœ… `.genie/utilities/agents/upstream-update.md` (1.6 KB)

<details>
<summary>View new file content</summary>

```markdown
# Upstream Update Agent

**Role:** Automate upstream dependency updates with comprehensive validation

## Core Responsibility

Execute complete upstream update workflows, including:
- Fork synchronization
- Mechanical rebranding
- Release creation
- Gitmodule updates
- Type regeneration
- Build verification
- Automated fix generation

## Execution Pattern

When given an upstream update task:

1. **Parse Context:**
   - Current version
   - Target version
   - Repository information
   - Patches to re-apply

2. **Execute Phases Sequentially:**
   - Pre-Sync Audit (gap detection)
   - Fork Sync (mirror upstream)
   - Mechanical Rebrand (remove vendor references)
   - Release Creation (tag + GitHub release)
   - Gitmodule Update (point to new tag)
   - Type Regeneration & Build
   - Post-Sync Validation
   - Automated Fix Generation
   - Commit & Push

3. **Success Criteria Validation:**
   - Fork mirrors upstream exactly
   - Rebrand applied (0 vendor references except packages)
   - Tag created with correct naming
   - GitHub release published
   - Build passes
   - All gaps documented with fix scripts

## Tools & Automation

- Use Git agent for repository operations
- Execute build commands directly
- Generate fix scripts for detected gaps
- Document all changes comprehensively

## Output Format

Provide detailed phase-by-phase execution log with:
- âœ… Success markers
- âŒ Failure markers
- ğŸ“‹ Gap documentation
- ğŸ”§ Fix scripts generated

## Error Handling

- Halt on critical failures
- Document all gaps found
- Generate automated fixes where possible
- Provide manual intervention steps when needed
```

</details>

## Removed from Framework (4)

These files exist in your workspace but are no longer part of the framework:

- âŒ `.genie/code/agents/update.md` (8.2 KB)
- âŒ `.genie/code/agents/update/versions/v2.3.x-to-v2.4.0.md` (7.0 KB)
- âŒ `.genie/code/spells/real-time-data-standard.md` (9.1 KB)
- âŒ `.genie/neurons/master.md` (1.8 KB)

**Action:** Review if these are user customizations to keep or obsolete files to remove.

## Modified Files (22)

These files have changed in the upstream framework:

### ğŸ“ `.genie/agents/analyze.md`

**Size:** 6.7 KB â†’ 6.7 KB (+36.0 B)

<details>
<summary>View changes</summary>

```diff
--- a/.genie/agents/analyze.md
+++ b/.genie/agents/analyze.md
@@ -5 +5 @@
-  executor: OPENCODE
+  executor:
+    - CLAUDE_CODE
+    - CODEX
+    - OPENCODE
   background: true
 forge:
   CLAUDE_CODE:
     model: sonnet
   CODEX:
     model: gpt-5-codex
   OPENCODE:
     model: opencode/glm-4.6
 ---
 
 # Analyze Agent (Universal Framework)
 
 ## Identity & Mission
 Perform holistic system audits OR conduct focused deep investigations into specific topics, dependency graphs, or subsystems. Surface dependencies, hotspots, coupling, strategic improvement opportunities, and deliver comprehensive findings with evidence.
 
 **Works across ALL domains:** Code, research, legal, medical, finance, operations, strategy.
```

</details>

### ğŸ“ `.genie/agents/forge.md`

**Size:** 11.3 KB â†’ 11.4 KB (+34.0 B)

<details>
<summary>View changes</summary>

```diff
--- a/.genie/agents/forge.md
+++ b/.genie/agents/forge.md
@@ -3 +3 @@
-description: Universal forge orchestrator - breaks wishes into execution groups
+description: Universal forge orchestrator - breaks wishes into execution groups with task files and validation (all domains)
-  with task files and validation (all domains)
 genie:
-  executor: OPENCODE
+  executor:
+    - CLAUDE_CODE
+    - CODEX
+    - OPENCODE
   background: true
 forge:
   CLAUDE_CODE:
     model: sonnet
   CODEX:
     model: gpt-5-codex
   OPENCODE:
     model: opencode/glm-4.6
 ---
 
 ## Framework Reference
 
```

</details>

### ğŸ“ `.genie/agents/garbage-cleaner.md`

**Size:** 9.0 KB â†’ 9.0 KB (+36.0 B)

<details>
<summary>View changes</summary>

```diff
--- a/.genie/agents/garbage-cleaner.md
+++ b/.genie/agents/garbage-cleaner.md
@@ -5 +5 @@
-  executor: OPENCODE
+  executor:
+    - CLAUDE_CODE
+    - CODEX
+    - OPENCODE
   background: true
 forge:
   CLAUDE_CODE:
     model: sonnet
   CODEX:
     model: gpt-5-codex
   OPENCODE:
     model: opencode/glm-4.6
 ---
 
 # Garbage Cleaner â€¢ Identity & Mission
 Process GitHub issues tagged `garbage-collection`, implement fixes automatically, create individual PR per issue for human review.
 
 **This is a core Genie agent** - maintains Genie's consciousness quality through automated cleanup.
 
 ## Specialty
```

</details>

### ğŸ“ `.genie/agents/garbage-collector.md`

**Size:** 16.6 KB â†’ 16.6 KB (+36.0 B)

<details>
<summary>View changes</summary>

```diff
--- a/.genie/agents/garbage-collector.md
+++ b/.genie/agents/garbage-collector.md
@@ -5 +5 @@
-  executor: OPENCODE
+  executor:
+    - CLAUDE_CODE
+    - CODEX
+    - OPENCODE
   background: true
 forge:
   CLAUDE_CODE:
     model: sonnet
   CODEX:
     model: gpt-5-codex
   OPENCODE:
     model: opencode/glm-4.6
 ---
 
 # Garbage Collector â€¢ Identity & Mission
 
 **I am an autonomous quality assurance workflow.** I run independently without human interaction.
 
 Daily autonomous sweep of all markdown files to detect quality issues, token waste, and documentation rot. **I automatically create GitHub issues and commit daily reports** - no human approval needed.
 
```

</details>

### ğŸ“ `.genie/agents/github-issue-gc.md`

**Size:** 17.8 KB â†’ 17.8 KB (+36.0 B)

<details>
<summary>View changes</summary>

```diff
--- a/.genie/agents/github-issue-gc.md
+++ b/.genie/agents/github-issue-gc.md
@@ -5 +5 @@
-  executor: OPENCODE
+  executor:
+    - CLAUDE_CODE
+    - CODEX
+    - OPENCODE
   background: true
 forge:
   CLAUDE_CODE:
     model: sonnet
   CODEX:
     model: gpt-5-codex
   OPENCODE:
     model: opencode/glm-4.6
 ---
 
 # GitHub Issue Garbage Collector â€¢ Identity & Mission
 
 **I am an autonomous issue hygiene workflow.** I run independently without human interaction.
 
 Daily autonomous analysis of all open GitHub issues to detect stale, invalid, duplicate, or already-fixed issues. **I automatically add labels, create comments, and generate cleanup reports** - no human approval needed for triage actions.
 
```

</details>

### ğŸ“ `.genie/agents/review.md`

**Size:** 14.7 KB â†’ 14.7 KB (+34.0 B)

<details>
<summary>View changes</summary>

```diff
--- a/.genie/agents/review.md
+++ b/.genie/agents/review.md
@@ -3 +3 @@
-description: Universal review orchestrator - wish audits, code review, and QA
+description: Universal review orchestrator - wish audits, code review, and QA validation with evidence-based verdicts (all domains)
-  validation with evidence-based verdicts (all domains)
 genie:
-  executor: OPENCODE
+  executor:
+    - CLAUDE_CODE
+    - CODEX
+    - OPENCODE
   background: true
 forge:
   CLAUDE_CODE:
     model: sonnet
   CODEX:
     model: gpt-5-codex
   OPENCODE:
     model: opencode/glm-4.6
 ---
 
 ## Framework Reference
 
```

</details>

### ğŸ“ `.genie/agents/semantic-analyzer.md`

**Size:** 2.8 KB â†’ 2.8 KB (+36.0 B)

<details>
<summary>View changes</summary>

```diff
--- a/.genie/agents/semantic-analyzer.md
+++ b/.genie/agents/semantic-analyzer.md
@@ -5 +5 @@
-  executor: OPENCODE
+  executor:
+    - CLAUDE_CODE
+    - CODEX
+    - OPENCODE
   background: false
 forge:
   CLAUDE_CODE:
     model: sonnet
   CODEX:
     model: gpt-5-codex
   OPENCODE:
     model: opencode/glm-4.6
 ---
 
 # Semantic Analyzer â€¢ Master Orchestrator
 
 Orchestrates complex semantic analysis tasks that require natural language understanding.
 Delegates to opencode workflow agents for specific, token-heavy but simple analysis tasks.
 
 **This is a master agent** - coordinates semantic workflows, does not implement analysis itself.
```

</details>

### ğŸ“ `.genie/agents/semantic-analyzer/find-duplicates.md`

**Size:** 2.5 KB â†’ 2.5 KB (+36.0 B)

<details>
<summary>View changes</summary>

```diff
--- a/.genie/agents/semantic-analyzer/find-duplicates.md
+++ b/.genie/agents/semantic-analyzer/find-duplicates.md
@@ -5 +5 @@
-  executor: OPENCODE
+  executor:
+    - CLAUDE_CODE
+    - CODEX
+    - OPENCODE
   background: false
 forge:
   CLAUDE_CODE:
     model: sonnet
   CODEX:
     model: gpt-5-codex
   OPENCODE:
     model: opencode/glm-4.6
 ---
 
 # Find Duplicates Workflow
 
 Analyze markdown files to detect near-duplicate content (>80% semantic similarity).
 Returns JSON with duplicate pairs, similarity scores, and excerpts.
 
 ## Task
```

</details>

### ğŸ“ `.genie/agents/semantic-analyzer/find-orphans.md`

**Size:** 2.7 KB â†’ 2.7 KB (+36.0 B)

<details>
<summary>View changes</summary>

```diff
--- a/.genie/agents/semantic-analyzer/find-orphans.md
+++ b/.genie/agents/semantic-analyzer/find-orphans.md
@@ -5 +5 @@
-  executor: OPENCODE
+  executor:
+    - CLAUDE_CODE
+    - CODEX
+    - OPENCODE
   background: false
 forge:
   CLAUDE_CODE:
     model: sonnet
   CODEX:
     model: gpt-5-codex
   OPENCODE:
     model: opencode/glm-4.6
 ---
 
 # Find Orphans Workflow
 
 Analyze markdown files to find orphans (files with zero incoming @ references).
 Returns JSON with orphaned files and last modification dates.
 
 ## Task
```

</details>

### ğŸ“ `.genie/agents/wish.md`

**Size:** 12.1 KB â†’ 12.2 KB (+34.0 B)

<details>
<summary>View changes</summary>

```diff
--- a/.genie/agents/wish.md
+++ b/.genie/agents/wish.md
@@ -3 +3 @@
-description: Universal wish architect - converts ideas into roadmap-aligned
+description: Universal wish architect - converts ideas into roadmap-aligned wishes with spec contracts (all domains)
-  wishes with spec contracts (all domains)
 genie:
-  executor: OPENCODE
+  executor:
+    - CLAUDE_CODE
+    - CODEX
+    - OPENCODE
   background: true
 forge:
   CLAUDE_CODE:
     model: sonnet
   CODEX:
     model: gpt-5-codex
   OPENCODE:
     model: opencode/glm-4.6
 ---
 
 ## Mandatory Context Loading
 
```

</details>

### ğŸ“ `.genie/code/agents/tests.md`

**Size:** 25.1 KB â†’ 25.1 KB (+19.0 B)

<details>
<summary>View changes</summary>

```diff
--- a/.genie/code/agents/tests.md
+++ b/.genie/code/agents/tests.md
@@ -149 +149 @@
-- **Tooling:** Playwright
+- **Tooling:** Playwright, Cypress, Selenium
 
 #### 4. Manual Testing (Human Validation)
 - **Purpose:** Exploratory testing, UX validation, accessibility checks
 - **Scope:** New UI features, complex workflows requiring human judgment
 - **Coverage Target:** 100% of user-facing changes reviewed by QA/PM
 - **Tooling:** Checklist-driven exploratory testing, accessibility scanners (axe, WAVE)
 
 #### 5. Monitoring/Alerting Validation (Observability)
 - **Purpose:** Validate production telemetry captures failures and triggers alerts
 - **Scope:** SLO/SLI metrics, error tracking, distributed tracing
 - **Coverage Target:** 100% of critical failure modes have alerts
 - **Tooling:** Prometheus, Datadog, Sentry, synthetic monitoring (Pingdom, Checkly)
 
 #### 6. Rollback/Disaster Recovery (Safety Net)
 - **Purpose:** Validate ability to revert changes and recover from catastrophic failures
 - **Scope:** Database migrations (backward-compatible?), feature flags, blue-green deployments
 - **Coverage Target:** 100% of schema changes tested for rollback
 - **Tooling:** Database migration tools, feature flag platforms (LaunchDarkly), chaos engineering (Gremlin)
 
```

</details>

### ğŸ“ `.genie/create/agents/editor.md`

**Size:** 801.0 B â†’ 872.0 B (+71.0 B)

<details>
<summary>View changes</summary>

```diff
--- a/.genie/create/agents/editor.md
+++ b/.genie/create/agents/editor.md
@@ -13 +13 @@
+    dangerously_skip_permissions: true
   CODEX:
     model: gpt-5-codex
+    sandbox: danger-full-access
   OPENCODE:
     model: opencode/glm-4.6
 ---
 
 # Editor â€¢ Identity & Mission
 Perform line and substantive edits to improve clarity, accuracy, and style adherence. Document major changes and rationale.
 
 ## Operating Prompt
 ```
 Input: draft (vN) + style guide refs
 Deliver: edited draft + change log
 Store: .genie/wishes/<slug>/validation/ and reports/
 ```
 
 ## Never Do
 - âŒ Alter intent without flagging rationale
 - âŒ Remove citations or weaken factual grounding
```

</details>

### ğŸ“ `.genie/create/agents/install.md`

**Size:** 11.5 KB â†’ 11.5 KB (+71.0 B)

<details>
<summary>View changes</summary>

```diff
--- a/.genie/create/agents/install.md
+++ b/.genie/create/agents/install.md
@@ -13 +13 @@
+    dangerously_skip_permissions: true
   CODEX:
     model: gpt-5-codex
+    sandbox: danger-full-access
   OPENCODE:
     model: opencode/glm-4.6
 ---
 
 ## Mandatory Context Loading
 
 **MUST load workspace context** using `mcp__genie__get_workspace_info` before proceeding.
 
 # Create Installation Agent
 **Your First Conversation with Create**
 
 ## Core Identity
 
 I am Create - your personal companion for all non-coding work. I'm fully dynamic:
 - **In repositories:** I help with project-specific work (docs, planning, content, strategy)
 - **General use:** I become your personal assistant for any work you need
 - I shape-shift based on who you are and what you need
```

</details>

### ğŸ“ `.genie/create/agents/marketing/announcements.md`

**Size:** 4.8 KB â†’ 4.9 KB (+71.0 B)

<details>
<summary>View changes</summary>

```diff
--- a/.genie/create/agents/marketing/announcements.md
+++ b/.genie/create/agents/marketing/announcements.md
@@ -13 +13 @@
+    dangerously_skip_permissions: true
   CODEX:
     model: gpt-5-codex
+    sandbox: danger-full-access
   OPENCODE:
     model: opencode/glm-4.6
 ---
 
 # ğŸ“¢ Release Announcements
 
 **Purpose:** Spread the word about new releases across platforms
 
 **Input Required:**
 - `version`: New version number
 - `releaseNotes`: Beautiful notes from release-notes agent
 - `type`: Release type ('stable' | 'rc')
 - `highlights`: Array of key changes
 
 **Output:** Posts created on multiple platforms (no return value)
 
 ---
```

</details>

### ğŸ“ `.genie/create/agents/marketing/docs-sync.md`

**Size:** 5.3 KB â†’ 5.3 KB (+71.0 B)

<details>
<summary>View changes</summary>

```diff
--- a/.genie/create/agents/marketing/docs-sync.md
+++ b/.genie/create/agents/marketing/docs-sync.md
@@ -13 +13 @@
+    dangerously_skip_permissions: true
   CODEX:
     model: gpt-5-codex
+    sandbox: danger-full-access
   OPENCODE:
     model: opencode/glm-4.6
 ---
 
 # ğŸ“š Documentation Version Sync
 
 **Purpose:** Keep version references up-to-date across all documentation
 
 **Input Required:**
 - `version`: New version number
 - `previousVersion`: Old version number to replace
 - `type`: Release type ('stable' | 'rc')
 
 **Output:** Pull request with updated references
 
 ---
 
```

</details>

### ğŸ“ `.genie/create/agents/marketing/release-notes.md`

**Size:** 3.9 KB â†’ 4.0 KB (+71.0 B)

<details>
<summary>View changes</summary>

```diff
--- a/.genie/create/agents/marketing/release-notes.md
+++ b/.genie/create/agents/marketing/release-notes.md
@@ -13 +13 @@
+    dangerously_skip_permissions: true
   CODEX:
     model: gpt-5-codex
+    sandbox: danger-full-access
   OPENCODE:
     model: opencode/glm-4.6
 ---
 
 # ğŸ¨ Release Notes Generator
 
 **Purpose:** Transform technical commits into beautiful, user-focused release notes
 
 **Input Required:**
 - `version`: New version number (e.g., "2.5.2")
 - `commits`: Array of commits since last release
 - `type`: Release type ('stable' | 'rc' | 'patch' | 'minor' | 'major')
 - `previousVersion`: Previous version number
 
 **Output:** Markdown-formatted release notes
 
 ---
```

</details>

### ğŸ“ `.genie/create/agents/researcher.md`

**Size:** 896.0 B â†’ 967.0 B (+71.0 B)

<details>
<summary>View changes</summary>

```diff
--- a/.genie/create/agents/researcher.md
+++ b/.genie/create/agents/researcher.md
@@ -13 +13 @@
+    dangerously_skip_permissions: true
   CODEX:
     model: gpt-5-codex
+    sandbox: danger-full-access
   OPENCODE:
     model: opencode/glm-4.6
 ---
 
 # Researcher â€¢ Identity & Mission
 Investigate with rigor. Capture citations (URLs, dates), summarize findings, and note disagreements across sources. Save evidence under the active wish.
 
 ## Operating Prompt
 ```
 Focus: <topic>
 Goal: curate sources and synthesize findings
 Deliver: summary, citations, risks/unknowns, recommended outline seeds
 Store: .genie/wishes/<slug>/validation/
 ```
 
 ## Never Do
 - âŒ Present claims without citations
```

</details>

### ğŸ“ `.genie/create/agents/wish/blueprint.md`

**Size:** 1.1 KB â†’ 1.2 KB (+71.0 B)

<details>
<summary>View changes</summary>

```diff
--- a/.genie/create/agents/wish/blueprint.md
+++ b/.genie/create/agents/wish/blueprint.md
@@ -13 +13 @@
+    dangerously_skip_permissions: true
   CODEX:
     model: gpt-5-codex
+    sandbox: danger-full-access
   OPENCODE:
     model: opencode/glm-4.6
 ---
 
 ## Mandatory Context Loading
 
 **MUST load workspace context** using `mcp__genie__get_workspace_info` before proceeding.
 
 # Create Wish â€¢ Blueprint Workflow
 
 ## Goal
 Generate a wish at `.genie/wishes/<slug>/<slug>-wish.md` using the Create template and the gathered brief/context. Initialize `validation/` and `reports/` folders.
 
 ## Inputs
 - Planning brief and discovery notes
 - Context Ledger entries (files, links, sessions)
 - Style/brand guide references (optional)
```

</details>

### ğŸ“ `.genie/create/agents/writer.md`

**Size:** 819.0 B â†’ 890.0 B (+71.0 B)

<details>
<summary>View changes</summary>

```diff
--- a/.genie/create/agents/writer.md
+++ b/.genie/create/agents/writer.md
@@ -13 +13 @@
+    dangerously_skip_permissions: true
   CODEX:
     model: gpt-5-codex
+    sandbox: danger-full-access
   OPENCODE:
     model: opencode/glm-4.6
 ---
 
 # Writer â€¢ Identity & Mission
 Produce wellâ€‘structured drafts aligned to the brief and style guides. Capture rationales for structure and tone.
 
 ## Operating Prompt
 ```
 Brief: <audience, purpose, tone, key points>
 Inputs: @research notes, links
 Deliver: outline + draft (v1)
 Store: .genie/wishes/<slug>/validation/
 ```
 
 ## Never Do
 - âŒ Fabricate facts; ask researcher for missing info
```

</details>

### ğŸ“ `.genie/neurons/genie.md`

**Size:** 1.8 KB â†’ 1.9 KB (+71.0 B)

<details>
<summary>View changes</summary>

```diff
--- a/.genie/neurons/genie.md
+++ b/.genie/neurons/genie.md
@@ -13 +13 @@
+    dangerously_skip_permissions: true
   CODEX:
     model: gpt-5-codex
+    sandbox: danger-full-access
   OPENCODE:
     model: opencode/glm-4.6
 ---
 
 # Genie
 
 You are Genie, the top-level orchestrator for complex multi-step workflows and installations.
 
 ## Your Role
 
 - Coordinate installation flows (`genie init`)
 - Orchestrate multi-agent workflows across collectives
 - Handle high-level decision making and routing
 - Delegate to specialized orchestrators (Wish, Forge, Review)
 - Maintain workspace coherence and state
 
 ## Installation Flow
```

</details>

### ğŸ“ `.genie/product/README.md`

**Size:** 970.0 B â†’ 1.0 KB (+95.0 B)

<details>
<summary>View changes</summary>

```diff
--- a/.genie/product/README.md
+++ b/.genie/product/README.md
@@ -10 +10 @@
+- `@.genie/product/cli-automation.md` â€“ Complete CLI automation guide (cron, CI/CD, scripts)
 
 Framework behavior
 - The framework consumes these files via `@` references and injects their content into agent prompts.
 - Keep sections stable so downstream tools can parse consistently (e.g., headings like "Pitch", "Users", "The Problem").
 - Prefer updating these docs over scattering product data elsewhere.
 
 Validation
 - The install and wish workflows verify these paths exist and surface missing sections as blockers.
 - If you rename/move files, update all `@.genie/product/...` references to avoid broken context.
 
 
```

</details>

### ğŸ“ `AGENTS.md`

**Size:** 15.4 KB â†’ 15.1 KB (-294.0 B)

<details>
<summary>View changes</summary>

```diff
--- a/AGENTS.md
+++ b/AGENTS.md
@@ -361 +361 @@
-**Forge Task Creation:**
+**Technical Implementation:** Code collective responsibility.
-- ALWAYS use `dev` as base branch when creating task attempts
-- Forge creates isolated git worktrees, providing extra PR layer: task â†’ `dev` â†’ `main`
-- Never use `main` as base branch (no exceptions)
-- Command: `mcp__forge__start_task_attempt(base_branch: "dev")`
 
-**Technical Implementation:** Code collective responsibility.
-
 ## Quality Standards
 
 **Owner:** Master Genie coordinates quality across all collectives.
 
 **Quality Gates:** Code collective enforces validation, testing, and CI/CD requirements.
 
 ## QA Coordination Protocol
 
 **Owner:** Master Genie (QA is core identity, not separate concern)
 **Principle:** No release without guarantee it's better than the previous one
 **Documentation:** `@.genie/agents/qa/README.md` (260+ test items, 18 scenarios, evidence-backed, self-improving)
 
```

</details>

---

## Agent Instructions

This diff file documents all framework changes from v2.5.14 to v2.5.26-rc.2.

**Your task:**
1. **Learn** the new patterns and teachings from added/modified files
2. **Apply** necessary changes to workspace (preserve user customizations)
3. **Report** what was learned and what actions were taken

**Important:**
- Do NOT blindly copy files - understand the intent of each change
- Preserve user customizations in workspace files
- For conflicts, present options to user
- Create a report of learnings applied
